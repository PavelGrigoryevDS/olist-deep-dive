{
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 4,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "remove-cell"
        ]
      },
      "source": [
        "%run ../../_pre_run.ipynb"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Exploration\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Table df_orders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at the information about the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders.explore.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initial Column Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will examine each column individually."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**order_id**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders.order_id.explore.info(plot=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**customer_id**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders.customer_id.explore.info(plot=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**order_status**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders.order_status.explore.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- 97% of all orders were delivered"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**order_purchase_dt**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders.order_purchase_dt.explore.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- In order_purchase_dt missing 4% of months, 10% of weeks, 18% of days\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**order_approved_dt**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders.order_approved_dt.explore.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- In order_approved_dt 160 missing values (<1% of total rows)\n",
        "- In order_approved_dt missing 4% of months, 11% of weeks, 15% of days"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**order_delivered_carrier_dt**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders.order_delivered_carrier_dt.explore.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- In order_delivered_carrier_dt 1.78k missing values (2% of total rows).\n",
        "- In order_delivered_carrier_dt missing 2% of weeks, 22% of days."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**order_delivered_customer_dt**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders.order_delivered_customer_dt.explore.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- In order_delivered_customer_dt 2.96k missing values (3% of total rows).\n",
        "- In order_delivered_customer_dt missing 3% of weeks, 12% of days."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**order_estimated_delivery_dt**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders.order_estimated_delivery_dt.explore.info(plot=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- In order_estimated_delivery_dt missing 4% of weeks, 41% of days."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Adding Temporary Dimensions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To study anomalies across different dimensions, we will add temporary metrics.\n",
        "\n",
        "We will prefix their names with 'tmp_' to indicate that these are temporary metrics to be removed later.\n",
        "\n",
        "They are temporary because the data may change after preprocessing.\n",
        "\n",
        "Therefore, the primary metrics will be created after preprocessing.\n",
        "\n",
        "Let’s check the initial DataFrame size and save it to ensure no data is lost later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(df_orders.shape[0])\n",
        "tmp_ids = df_orders.order_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_reviews = (\n",
        "    df_reviews.groupby('order_id', as_index=False)\n",
        "    .agg(tmp_avg_reviews_score = ('review_score', 'mean'))\n",
        ")\n",
        "tmp_df_reviews['tmp_avg_reviews_score'] = np.floor(tmp_df_reviews['tmp_avg_reviews_score']).astype(int).astype('category')\n",
        "\n",
        "tmp_df_payments = (\n",
        "    df_payments.groupby('order_id', as_index=False)\n",
        "    .agg(tmp_payment_types = ('payment_type', lambda x: ', '.join(x.unique())))\n",
        ")\n",
        "tmp_df_items = (\n",
        "    df_items.merge(df_products, on='product_id', how='left')\n",
        "    .assign(product_category_name = lambda x: x['product_category_name'].cat.add_categories(['missed in df_products']))\n",
        "    .fillna({'product_category_name': 'missed in df_products'})\n",
        "    .groupby('order_id', as_index=False)\n",
        "    .agg(tmp_product_categories = ('product_category_name', lambda x: ', '.join(x.unique())))\n",
        ")\n",
        "\n",
        "df_orders = (\n",
        "    df_orders.merge(tmp_df_reviews, on='order_id', how='left')\n",
        "    .merge(tmp_df_payments, on='order_id', how='left')\n",
        "    .merge(tmp_df_items, on='order_id', how='left')\n",
        "    .merge(df_customers[['customer_id', 'customer_state']], on='customer_id', how='left')\n",
        "    .rename(columns={'customer_state': 'tmp_customer_state'})\n",
        ")\n",
        "\n",
        "df_orders['tmp_product_categories'] = df_orders['tmp_product_categories'].fillna('Missing in Items').astype('category')\n",
        "\n",
        "df_orders['tmp_payment_types'] = df_orders['tmp_payment_types'].fillna('Missing in Pays').astype('category')\n",
        "\n",
        "df_orders['tmp_order_purchase_month'] = df_orders['order_purchase_dt'].dt.month_name().fillna('Missing purchase dt').astype('category')\n",
        "\n",
        "df_orders['tmp_order_purchase_weekday'] = df_orders['order_purchase_dt'].dt.day_name().fillna('Missing purchase dt').astype('category')\n",
        "\n",
        "conditions = [\n",
        "    df_orders['order_purchase_dt'].isna()                      \n",
        "    , df_orders['order_purchase_dt'].dt.hour.between(4,11)\n",
        "    , df_orders['order_purchase_dt'].dt.hour.between(12,16)\n",
        "    , df_orders['order_purchase_dt'].dt.hour.between(17,22)\n",
        "    , df_orders['order_purchase_dt'].dt.hour.isin([23, 0, 1, 2, 3])\n",
        "]\n",
        "choices = ['Missing purchase dt', 'Morning', 'Afternoon', 'Evening', 'Night']\n",
        "df_orders['tmp_purchase_time_of_day'] = np.select(conditions, choices, default='Missing purchase dt')\n",
        "df_orders['tmp_purchase_time_of_day'] = df_orders['tmp_purchase_time_of_day'].astype('category')\n",
        "\n",
        "conditions = [\n",
        "    df_orders['order_delivered_customer_dt'].isna() | df_orders['order_estimated_delivery_dt'].isna()\n",
        "    , df_orders['order_delivered_customer_dt'] > df_orders['order_estimated_delivery_dt']            \n",
        "    , df_orders['order_delivered_customer_dt'] <= df_orders['order_estimated_delivery_dt']                           \n",
        "]\n",
        "choices = ['Missing delivery dt', 'Delayed', 'Not Delayed']\n",
        "df_orders['tmp_is_delayed'] = np.select(conditions, choices, default='Missing delivery dt')\n",
        "df_orders['tmp_is_delayed'] = df_orders['tmp_is_delayed'].astype('category')\n",
        "\n",
        "conditions = [\n",
        "    df_orders['order_status'].isna(), \n",
        "    df_orders['order_status'] == 'Delivered',               \n",
        "    df_orders['order_status'] != 'Delivered',  \n",
        "]\n",
        "choices = ['Missing Status', 'Delivered', 'Not Delivered']\n",
        "df_orders['tmp_is_delivered'] = np.select(conditions, choices, default='Missing Status')\n",
        "df_orders['tmp_is_delivered'] = df_orders['tmp_is_delivered'].astype('category')\n",
        "\n",
        "del tmp_df_reviews, tmp_df_payments, tmp_df_items"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Verified that nothing was lost."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "set(df_orders.order_id) == set(tmp_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "All good."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exploring Missing Values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s examine which columns contain missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders.explore.anomalies_report(\n",
        "    anomaly_type='missing'\n",
        "    , width=600\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**\n",
        "- Missing values in these columns likely belong to orders that did not reach a certain status."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will analyze missing values in each column separately."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Missing in order_approved_dt**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_miss = df_orders[df_orders['order_approved_dt'].isna()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s examine missing values in payment approval time over time.\n",
        "Time will be based on order creation time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders['order_approved_dt'].explore.anomalies_over_time(\n",
        "    time_column='order_purchase_dt'\n",
        "    , anomaly_type='missing'\n",
        "    , freq='W'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**\n",
        "\n",
        "- In February 2017 and August 2018, there was a spike in orders missing payment approval timestamps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s analyze by order status."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders['order_approved_dt'].explore.anomalies_by_categories(\n",
        "    anomaly_type='missing'\n",
        "    , pct_diff_threshold=-100\n",
        "    , include_columns='order_status'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**\n",
        "\n",
        "- Missing values in the \"canceled\" and \"created\" statuses are logical.\n",
        "- However, 14 missing values in order_approved_dt for orders with \"delivered\" status are unusual."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s examine these 14 delivered orders with missing order_approved_dt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_miss[lambda x: x.order_status == 'Delivered']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- All delivered orders with missing order_approved_dt used \"boleto\" as the payment method. This may be a characteristic of \"boleto\" usage.\n",
        "- All these orders were placed in January and February 2017. There may have been a system issue where approval timestamps were not saved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s examine the 5 created orders that have missing values in the payment approval time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at 5 \"created\" orders with missing payment approval timestamps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_miss[lambda x: x.order_status == 'Created']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Orders with \"created\" status and missing payment approval timestamps were placed long ago and never delivered. The data may not have been processed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s analyze by average order review score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders['order_approved_dt'].explore.anomalies_by_categories(\n",
        "    anomaly_type='missing'\n",
        "    , pct_diff_threshold=-100\n",
        "    , include_columns='tmp_avg_reviews_score'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**\n",
        "- The difference in proportions is significantly higher for score 1. These orders were likely not delivered."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s examine a word cloud from review messages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_miss = tmp_miss.merge(df_reviews, on='order_id', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_miss.viz.wordcloud('review_comment_message')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Many words relate to delivery."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s analyze the sentiment of the text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_miss.analysis.sentiment('review_comment_message')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- The sentiment is not predominantly negative."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s randomly sample 20 review comments.\n",
        "We’ll repeat this several times."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "messages = (\n",
        "    tmp_miss['review_comment_message']\n",
        "    .dropna()\n",
        "    .sample(20)\n",
        "    .tolist()\n",
        ")\n",
        "display(messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**\n",
        "\n",
        "- Based on review messages, many orders were not delivered, but a significant number were delivered.\n",
        "- Therefore, missing payment approval timestamps cannot be assumed to indicate order cancellation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s analyze by payment type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders['order_approved_dt'].explore.anomalies_by_categories(\n",
        "    anomaly_type='missing'\n",
        "    , pct_diff_threshold=-100\n",
        "    , include_columns='tmp_payment_types'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**\n",
        "\n",
        "- The proportion of \"voucher\" payments in missing values has increased significantly. This payment type is notably more frequent in missing values.\n",
        "- The \"voucher\" payment type has a stronger correlation with missing payment approval timestamps. This is likely a characteristic of this payment method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s analyze by month."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders['order_approved_dt'].explore.anomalies_by_categories(\n",
        "    anomaly_type='missing'\n",
        "    , pct_diff_threshold=-100\n",
        "    , include_columns='tmp_order_purchase_month'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**\n",
        "- August has a noticeably higher proportion of missing values than other months. This is also visible in the graph above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Missing Values in order_delivered_carrier_dt**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_miss = df_orders[df_orders['order_delivered_carrier_dt'].isna()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s examine the distribution of missing values in the carrier handover time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders['order_delivered_carrier_dt'].explore.anomalies_over_time(\n",
        "    time_column='order_purchase_dt'\n",
        "    , anomaly_type='missing'\n",
        "    , freq='W'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- In November 2017, there was a spike in orders missing carrier handover timestamps. This may be related to Black Friday."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s analyze by order status."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders['order_delivered_carrier_dt'].explore.anomalies_by_categories(\n",
        "    anomaly_type='missing'\n",
        "    , pct_diff_threshold=-100\n",
        "    , include_columns='order_status'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**\n",
        "- There are 2 delivered orders with missing order_delivered_carrier_dt.\n",
        "- All orders with \"unavailable\" status have missing order_delivered_carrier_dt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s examine these 2 delivered orders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_miss[lambda x: x.order_status == 'Delivered'].merge(df_payments, on='order_id', how='left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Both orders with missing order_delivered_carrier_dt were paid via credit card."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s analyze by average review score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders['order_delivered_carrier_dt'].explore.anomalies_by_categories(\n",
        "    anomaly_type='missing'\n",
        "    , pct_diff_threshold=-100\n",
        "    , include_columns='tmp_avg_reviews_score'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**\n",
        "\n",
        "- The difference in proportions is significantly higher for score 1. These orders were likely not delivered.\n",
        "- Review score 1 has the strongest correlation with missing carrier handover timestamps. This suggests these orders were not delivered, and customers were highly dissatisfied."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s examine a word cloud from review messages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_miss = tmp_miss.merge(df_reviews, on='order_id', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_miss.viz.wordcloud('review_comment_message')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Many words relate to delivery."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s analyze the sentiment of the text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_miss.analysis.sentiment('review_comment_message')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Negative reviews outnumber positive ones, and the boxplot body lies mostly below 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s randomly sample 20 review comments.\n",
        "We’ll repeat this several times."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "messages = (\n",
        "    tmp_miss['review_comment_message']\n",
        "    .dropna()\n",
        "    .sample(20)\n",
        "    .tolist()\n",
        ")\n",
        "display(messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**\n",
        "\n",
        "- Based on review messages, many orders were not delivered, but a significant number were delivered.\n",
        "- Orders with missing carrier handover timestamps were more frequently undelivered compared to those with missing payment approval timestamps.\n",
        "- Some products may have been out of stock, and sellers did not hand them over to carriers.\n",
        "- However, since many orders were still delivered, missing values cannot be assumed to indicate order cancellation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s analyze by customer state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders['order_delivered_carrier_dt'].explore.anomalies_by_categories(\n",
        "    anomaly_type='missing'\n",
        "    , include_columns='tmp_customer_state'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**\n",
        "- The difference in proportions is slightly higher in São Paulo compared to other states."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Missing Values in order_delivered_customer_dt**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_miss = df_orders[df_orders['order_delivered_customer_dt'].isna()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s examine the distribution of missing values in customer delivery time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders['order_delivered_customer_dt'].explore.anomalies_over_time(\n",
        "    time_column='order_purchase_dt'\n",
        "    , anomaly_type='missing'\n",
        "    , freq='W'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- In November 2017, there was a spike in orders missing customer delivery timestamps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s analyze by order status."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders['order_delivered_customer_dt'].explore.anomalies_by_categories(\n",
        "    anomaly_type='missing'\n",
        "    , pct_diff_threshold=-100\n",
        "    , include_columns='order_status'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**\n",
        "- There are 8 orders with \"delivered\" status but missing delivery timestamps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s analyze by customer state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders['order_delivered_customer_dt'].explore.anomalies_by_categories(\n",
        "    anomaly_type='missing'\n",
        "    , include_columns='tmp_customer_state'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**\n",
        "- The difference in proportions is slightly higher in Rio de Janeiro."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s examine these 8 delivered orders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_miss[lambda x: x.order_status == 'Delivered'].merge(df_payments, on='order_id', how='left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- 7 out of 8 orders with missing order_delivered_customer_dt were paid via credit card, and 1 was paid via debit card."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s analyze by average review score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders['order_delivered_customer_dt'].explore.anomalies_by_categories(\n",
        "    anomaly_type='missing'\n",
        "    , pct_diff_threshold=-100\n",
        "    , include_columns='tmp_avg_reviews_score'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**\n",
        "- The difference in proportions is significantly higher for score 1. These orders were likely not delivered."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s examine a word cloud from review messages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_miss = tmp_miss.merge(df_reviews, on='order_id', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_miss.viz.wordcloud('review_comment_message')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Many words relate to delivery."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s analyze the sentiment of the text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_miss.analysis.sentiment('review_comment_message')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Negative reviews outnumber positive ones, and the boxplot body lies mostly below 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s randomly sample 20 review comments.  \n",
        "We’ll repeat this several times."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "messages = (\n",
        "    tmp_miss['review_comment_message']\n",
        "    .dropna()\n",
        "    .sample(20)\n",
        "    .tolist()\n",
        ")\n",
        "display(messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**\n",
        "\n",
        "- Based on review messages, some orders were not delivered, but this is less frequent than with missing payment approval or carrier handover timestamps.\n",
        "- Many messages confirm order receipt. Thus, these orders cannot be assumed canceled."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "del tmp_miss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Anomalies in Order Status"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We have many orders with statuses other than \"delivered.\" This is unusual. Let's investigate this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's examine by status."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders.order_status.value_counts()  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at missing values in the timestamps by order status."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "columns = [\n",
        "    \"order_status\",\n",
        "    \"order_purchase_dt\",\n",
        "    \"order_approved_dt\",\n",
        "    \"order_delivered_carrier_dt\",\n",
        "    \"order_delivered_customer_dt\",\n",
        "    \"order_estimated_delivery_dt\",\n",
        "]\n",
        "(\n",
        "    df_orders[columns].pivot_table(\n",
        "        index='order_status',\n",
        "        aggfunc=lambda x: x.isna().sum(),\n",
        "        observed=True,\n",
        "    )\n",
        "    .reset_index()\n",
        "    [columns]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at the number of orders without the delivered status over time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = dict(\n",
        "    order_purchase_dt = 'Date',\n",
        "    order_id = 'Number of Orders', \n",
        "    order_status = 'Order Status', \n",
        ")\n",
        "df_orders[lambda x: x.order_status != 'Delivered'].viz.line(\n",
        "    x='order_purchase_dt',\n",
        "    y='order_id',\n",
        "    color='order_status',\n",
        "    agg_func='nunique',\n",
        "    freq='ME',\n",
        "    labels=labels,\n",
        "    markers=True,\n",
        "    title='Number of Orders without Delivered Status by Month and Order Status',   \n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- In March and April 2018, there was a sharp spike in orders stuck in the \"shipped\" status.\n",
        "- In February and August 2018, there were spikes in the \"canceled\" status.\n",
        "- In November 2017, there was a spike in the \"unavailable\" status. This month included Black Friday."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's examine each status separately."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**created**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at the rows in the dataframe with orders that have the status ‘created’."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders[lambda x: x.order_status == 'Created']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- One order has a rating of 5, while four orders have a rating of 1.\n",
        "- The process stops after purchase, before payment approval."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at the review messages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "messages = (\n",
        "    df_orders[lambda x: x.order_status == 'Created']\n",
        "    .merge(df_reviews, on='order_id', how='left')\n",
        "    ['review_comment_message']\n",
        "    .tolist()\n",
        ")\n",
        "display(messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Based on review comments, these orders were not delivered."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**approved**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at the rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders[lambda x: x.order_status == 'Approved']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- One order received a rating of 1, the other a 4.\n",
        "- The process stops after payment approval, before carrier handover."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at the review messages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "messages = (\n",
        "    df_orders[lambda x: x.order_status == 'Approved']\n",
        "    .merge(df_reviews, on='order_id', how='left')\n",
        "    ['review_comment_message']\n",
        "    .tolist()\n",
        ")\n",
        "display(messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- No comments were left for these orders."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**processing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at orders with the status ‘processing’ by month."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders['order_status'].explore.anomalies_over_time(\n",
        "    time_column='order_purchase_dt'\n",
        "    , custom_mask=df_orders.order_status == 'Processing'\n",
        "    , freq='ME'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at the count of each order status."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_anomal = df_orders[lambda x: x.order_status == 'Processing']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(\n",
        "    tmp_anomal[['order_purchase_dt', 'order_approved_dt', 'order_delivered_carrier_dt', 'order_delivered_customer_dt', 'order_estimated_delivery_dt']]\n",
        "    .count()    \n",
        "    .to_frame('count')\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- The process stops after payment approval, before carrier handover."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at it broken down by the average order rating."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders['order_status'].explore.anomalies_by_categories(\n",
        "    custom_mask=df_orders.order_status == 'Processing'\n",
        "    , include_columns='tmp_avg_reviews_score'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- 86% of orders with \"processing\" status have a rating of 1.\n",
        "- 6% of orders have a rating of 2.\n",
        "- Customers are clearly dissatisfied."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at it broken down by payment type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders['order_status'].explore.anomalies_by_categories(\n",
        "    custom_mask=df_orders.order_status == 'Processing'\n",
        "    , include_columns='tmp_payment_types'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**\n",
        "- The \"boleto\" payment type has a slightly higher proportion difference."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s randomly sample 20 review comments.  \n",
        "We’ll repeat this several times."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_anomal = tmp_anomal.merge(df_reviews, on='order_id', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "messages = (\n",
        "    tmp_anomal['review_comment_message']\n",
        "    .dropna()\n",
        "    .sample(20)\n",
        "    .tolist()\n",
        ")\n",
        "display(messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Based on review messages, orders were not delivered.\n",
        "- Some reviews mention items being out of stock."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s examine a word cloud from review messages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_anomal.viz.wordcloud('review_comment_message')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Most words relate to delivery."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s analyze the sentiment of the text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_anomal.analysis.sentiment('review_comment_message')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Negative reviews significantly outnumber positive ones, and the boxplot lies in the negative zone."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**invoiced**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at orders with the status ‘invoiced’ by month."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders['order_status'].explore.anomalies_over_time(\n",
        "    time_column='order_purchase_dt'\n",
        "    , custom_mask=df_orders.order_status == 'Invoiced'\n",
        "    , freq='ME'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at the count of each order status."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_anomal = df_orders[lambda x: x.order_status == 'Invoiced']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(\n",
        "    tmp_anomal[['order_purchase_dt', 'order_approved_dt', 'order_delivered_carrier_dt', 'order_delivered_customer_dt', 'order_estimated_delivery_dt']]\n",
        "    .count()    \n",
        "    .to_frame('count')\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- The process stops after payment approval, before carrier handover."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at it broken down by the average order rating."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders['order_status'].explore.anomalies_by_categories(\n",
        "    custom_mask=df_orders.order_status == 'Invoiced'\n",
        "    , include_columns='tmp_avg_reviews_score'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- 74% of orders with \"invoiced\" status have a rating of 1.\n",
        "- 9% of orders have a rating of 2.\n",
        "- Customers are clearly dissatisfied."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s randomly sample 20 review comments.  \n",
        "We’ll repeat this several times."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_anomal = tmp_anomal.merge(df_reviews, on='order_id', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "messages = (\n",
        "    tmp_anomal['review_comment_message']\n",
        "    .dropna()\n",
        "    .sample(20)\n",
        "    .tolist()\n",
        ")\n",
        "display(messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Review messages indicate orders were not delivered.\n",
        "- Some reviews mention items being out of stock."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s examine a word cloud from review messages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_anomal.viz.wordcloud('review_comment_message')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Many words relate to delivery."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s analyze the sentiment of the text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_anomal.analysis.sentiment('review_comment_message')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Negative reviews significantly outnumber positive ones, and the boxplot mostly lies below 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**unavailable**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at orders with the status ‘unavailable’ by month."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders['order_status'].explore.anomalies_over_time(\n",
        "    time_column='order_purchase_dt'\n",
        "    , custom_mask=df_orders.order_status == 'Unavailable'\n",
        "    , freq='ME'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at the count of each order status."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_anomal = df_orders[lambda x: x.order_status == 'Unavailable']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "( \n",
        "    tmp_anomal[['order_purchase_dt', 'order_approved_dt', 'order_delivered_carrier_dt', 'order_delivered_customer_dt', 'order_estimated_delivery_dt']]\n",
        "    .count()    \n",
        "    .to_frame('count') \n",
        ") "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- The process stops after payment approval, before carrier handover."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look by the customer’s state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders['order_status'].explore.anomalies_by_categories(\n",
        "    custom_mask=df_orders.order_status == 'Unavailable'\n",
        "    , pct_diff_threshold=1\n",
        "    , include_columns='tmp_customer_state'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- The proportion of missing values in São Paulo is higher than in the full dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look  by product category."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders['order_status'].explore.anomalies_by_categories(\n",
        "    custom_mask=df_orders.order_status == 'Unavailable'\n",
        "    , pct_diff_threshold=0\n",
        "    , include_columns='tmp_product_categories'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- 99% of orders lack a category, meaning they are not in the items table."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at it broken down by payment type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders['order_status'].explore.anomalies_by_categories(\n",
        "    custom_mask=df_orders.order_status == 'Unavailable'\n",
        "    , pct_diff_threshold=0\n",
        "    , include_columns='tmp_payment_types'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- The \"boleto\" payment type has a slightly higher proportion difference."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at it broken down by the average order rating."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders['order_status'].explore.anomalies_by_categories(\n",
        "    custom_mask=df_orders.order_status == 'Unavailable'\n",
        "    , pct_diff_threshold=0\n",
        "    , include_columns='tmp_avg_reviews_score'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- The difference in proportions is much higher for a rating of 1.\n",
        "- 78% of orders with \"unavailable\" status have a rating of 1.\n",
        "- 8% of orders have a rating of 2.\n",
        "- Customers are clearly dissatisfied."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s randomly sample 20 review comments.  \n",
        "We’ll repeat this several times."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_anomal = tmp_anomal.merge(df_reviews, on='order_id', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "messages = (\n",
        "    tmp_anomal['review_comment_message']\n",
        "    .dropna()\n",
        "    .sample(20)\n",
        "    .tolist()\n",
        ")\n",
        "display(messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Review messages indicate orders were not delivered.\n",
        "- Some reviews mention items being out of stock."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s examine a word cloud from review messages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_anomal.viz.wordcloud('review_comment_message')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Many words relate to delivery."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s analyze the sentiment of the text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_anomal.analysis.sentiment('review_comment_message')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Negative reviews outnumber positive ones, and the boxplot mostly lies below 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**canceled**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at orders with the status ‘canceled’ by month."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders['order_status'].explore.anomalies_over_time(\n",
        "    time_column='order_purchase_dt'\n",
        "    , custom_mask=df_orders.order_status == 'Canceled'\n",
        "    , freq='ME'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Order cancellation can occur at different stages, so there may be missing values at various points. \n",
        "\n",
        "Let’s look at the missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_anomal = df_orders[lambda x: x.order_status == 'Canceled']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_anomal.explore.detect_anomalies()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Conversion at different stages**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at the count of different order status timestamps. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s check if there are any missing values between the dates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mask = tmp_anomal['order_delivered_carrier_dt'].isna() & tmp_anomal['order_delivered_customer_dt'].notna()\n",
        "tmp_anomal.loc[mask, 'order_delivered_carrier_dt'] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mask = tmp_anomal['order_approved_dt'].isna() & tmp_anomal['order_delivered_carrier_dt'].notna()\n",
        "tmp_anomal.loc[mask, 'order_approved_dt']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "All good."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_funnel = ( \n",
        "    tmp_anomal[['order_purchase_dt', 'order_approved_dt', 'order_delivered_carrier_dt', 'order_delivered_customer_dt']]\n",
        "    .count()    \n",
        "    .to_frame('count') \n",
        "    .assign(share = lambda x: (x['count']*100 / x['count']['order_purchase_dt']).round(1).astype(str) + '%')\n",
        "    .reset_index(names='stage')\n",
        ") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "px.funnel(\n",
        "    tmp_funnel, \n",
        "    x='count', \n",
        "    y='stage', \n",
        "    text='share',\n",
        "    width=600,\n",
        "    title='Conversion of Different Order Stages with \"Canceled\" Status'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- The process stops at different stages, most often between payment approval and carrier handover."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at the conversion at each stage by month. \n",
        "\n",
        "For this, we will count the number of canceled orders with specific timestamps in each period and divide by the number of canceled orders at the time of purchase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_res_df = (\n",
        "    tmp_anomal.resample('ME', on='order_purchase_dt')\n",
        "    .agg(\n",
        "        purchase = ('order_id', 'count')\n",
        "        , approved = ('order_approved_dt', 'count')\n",
        "        , delivered_carrier = ('order_delivered_carrier_dt', 'count')\n",
        "        , delivered_customer = ('order_delivered_customer_dt', 'count')\n",
        "    )\n",
        ") \n",
        "tmp_res_df = tmp_res_df.div(tmp_res_df['purchase'], axis=0)\n",
        "tmp_res_df = (  \n",
        "    tmp_res_df.reset_index(names='date')\n",
        "    .melt(id_vars='date', var_name='date_type', value_name='count')\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at the non-normalized values. That is, divide each value (count with a specific timestamp) by the total value for the period."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = dict(\n",
        "    date = 'Date',\n",
        "    date_type = 'Date Type',\n",
        "    count = 'Conversion'\n",
        ")\n",
        "tmp_res_df.viz.line(\n",
        "    x='date'\n",
        "    , y='count'\n",
        "    , color='date_type'\n",
        "    , labels=labels\n",
        "    , title='Conversion of Different Order Stages with \"Canceled\" Status by Month'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Canceled orders almost never have delivery timestamps, which is logical.\n",
        "- From December 2017 to March 2018, there was a significant spike in canceled orders that had carrier handover timestamps but no delivery timestamps, indicating delivery issues during this period.\n",
        "- About 80% of canceled orders have payment approval timestamps, but this proportion increased significantly starting January 2018, approaching 100%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Number of Last Stages**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at the last stage to which orders with the status ‘canceled’ reach over time. \n",
        "\n",
        "For this:\n",
        "- transform the wide table into a long one, making the name of the time variable a category;\n",
        "- remove missing values in the time (this will be the variable with the value after melt);\n",
        "- convert these categories into a categorical type in pandas and specify the order;\n",
        "- group by order;\n",
        "- take the first time in each group (all entries in the group will have the same time);\n",
        "- take the maximum stage (since we specified the order, this will be the last stage of the order)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_orders_canceled = df_orders[lambda x: x.order_status == 'Canceled']\n",
        "tmp_df_orders_canceled['tmp_date'] = tmp_df_orders_canceled['order_purchase_dt']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_orders_canceled = (\n",
        "    tmp_df_orders_canceled.rename(\n",
        "        columns={\n",
        "            'order_purchase_dt': 'purchase'\n",
        "            , 'order_approved_dt': 'approved'\n",
        "            , 'order_delivered_carrier_dt': 'delivered_carrier'\n",
        "            , 'order_delivered_customer_dt': 'delivered_customer'\n",
        "        }\n",
        "    )\n",
        "    .melt(\n",
        "        id_vars=['tmp_date', 'order_id']\n",
        "        , value_vars=['purchase', 'approved', 'delivered_carrier', 'delivered_customer']\n",
        "        , var_name='date_stage'\n",
        "    )\n",
        "    .dropna(subset='value')\n",
        "    .drop('value', axis=1)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "date_stage_order = ['purchase', 'approved', 'delivered_carrier', 'delivered_customer']\n",
        "tmp_df_orders_canceled['date_stage'] = (\n",
        "    tmp_df_orders_canceled['date_stage']\n",
        "    .astype('category')\n",
        "    .cat.reorder_categories(date_stage_order, ordered=True)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_orders_canceled = (\n",
        "    tmp_df_orders_canceled.groupby('order_id', as_index=False)\n",
        "    .agg(\n",
        "        tmp_date = ('tmp_date', 'first')\n",
        "        , last_date_stage = ('date_stage', 'max')\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at it over time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = dict(\n",
        "    date = 'Date',\n",
        "    order_id = 'Number of Orders',\n",
        "    last_date_stage = 'Last Stage'\n",
        ")\n",
        "tmp_df_orders_canceled.viz.line(\n",
        "    x='tmp_date'\n",
        "    , y='order_id'\n",
        "    , color='last_date_stage'\n",
        "    , agg_func='nunique'\n",
        "    , freq='ME'\n",
        "    , labels=labels\n",
        "    , markers=True\n",
        "    , title='Number of Orders by Month and Last Stage'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- In most months, the process stops after payment approval.\n",
        "- From December 2017 to March 2018, there was a spike in orders that stopped after carrier handover.\n",
        "- In August 2018, there was a sharp peak in orders that stopped immediately after purchase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look by the customer’s state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_anomal = df_orders[lambda x: x.order_status == 'Canceled']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders['order_status'].explore.anomalies_by_categories(\n",
        "   custom_mask=df_orders.order_status == 'Canceled'\n",
        "   , pct_diff_threshold=0\n",
        "    , include_columns='tmp_customer_state'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- The proportion of missing values in São Paulo is significantly higher than in the full dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look  by product category."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders['order_status'].explore.anomalies_by_categories(\n",
        "   custom_mask=df_orders.order_status == 'Canceled'\n",
        "   , pct_diff_threshold=1\n",
        "    , include_columns='tmp_product_categories'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Missing product categories have a much higher proportion difference, possibly due to items being out of stock."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at it broken down by payment type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders['order_status'].explore.anomalies_by_categories(\n",
        "   custom_mask=df_orders.order_status == 'Canceled'\n",
        "   , pct_diff_threshold=0\n",
        "    , include_columns='tmp_payment_types'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- The \"voucher\" payment type has a noticeably higher proportion difference."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at it broken down by the average order rating."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders['order_status'].explore.anomalies_by_categories(\n",
        "   custom_mask=df_orders.order_status == 'Canceled'\n",
        "   , pct_diff_threshold=0\n",
        "    , include_columns='tmp_avg_reviews_score'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- 69% of orders with \"canceled\" status have a rating of 1.\n",
        "- 7% of orders have a rating of 2.\n",
        "- Customers are clearly dissatisfied."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s randomly sample 20 review comments.  \n",
        "We’ll repeat this several times."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_anomal = tmp_anomal.merge(df_reviews, on='order_id', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "messages = (\n",
        "    tmp_anomal['review_comment_message']\n",
        "    .dropna()\n",
        "    .sample(20)\n",
        "    .tolist()\n",
        ")\n",
        "display(messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Review messages indicate orders were not delivered.\n",
        "- Some reviews mention items being out of stock."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s examine a word cloud from review messages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_anomal.viz.wordcloud('review_comment_message')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Many words relate to delivery."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s analyze the sentiment of the text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_anomal.analysis.sentiment('review_comment_message')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Negative messages significantly outnumber positive ones, and the boxplot lies below 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**shipped**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at the number of orders with the status ‘delivered’ by month."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders['order_status'].explore.anomalies_over_time(\n",
        "    time_column='order_purchase_dt'\n",
        "    , custom_mask=df_orders.order_status == 'Shipped'\n",
        "    , freq='ME'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at the count of each order status."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_anomal = df_orders[lambda x: x.order_status == 'Shipped']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(\n",
        "    tmp_anomal[['order_purchase_dt', 'order_approved_dt', 'order_delivered_carrier_dt', 'order_delivered_customer_dt', 'order_estimated_delivery_dt']]\n",
        "    .count()    \n",
        "    .to_frame('count')\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- The process stops after carrier handover, before customer delivery."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look by the customer’s state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders['order_status'].explore.anomalies_by_categories(\n",
        "    custom_mask=df_orders.order_status == 'Shipped'\n",
        "    , pct_diff_threshold=1\n",
        "    , include_columns='tmp_customer_state'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- The proportion of missing values in Rio de Janeiro is significantly higher than in the full dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at it broken down by the average order rating."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders['order_status'].explore.anomalies_by_categories(\n",
        "    custom_mask=df_orders.order_status == 'Shipped'\n",
        "    , pct_diff_threshold=1\n",
        "    , include_columns='tmp_avg_reviews_score'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- 62% of orders with \"shipped\" status have a rating of 1.\n",
        "- 8% of orders have a rating of 2.\n",
        "- Customers are clearly dissatisfied."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s randomly sample 20 review comments.  \n",
        "We’ll repeat this several times."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_anomal = tmp_anomal.merge(df_reviews, on='order_id', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "messages = (\n",
        "    tmp_anomal['review_comment_message']\n",
        "    .dropna()\n",
        "    .sample(20)\n",
        "    .tolist()\n",
        ")\n",
        "display(messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Review messages indicate most orders were not delivered."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s examine a word cloud from review messages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_anomal.viz.wordcloud('review_comment_message')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Many words relate to delivery."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s analyze the sentiment of the text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_anomal.analysis.sentiment('review_comment_message')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Negative messages outnumber positive ones, and the boxplot mostly lies below 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Status and Delivery Mismatches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Delivery status missing but delivery timestamp present**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's check if there are orders without \"delivered\" status that still have a delivery timestamp."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders[lambda x: (x.order_status != 'Delivered') & ~x.order_delivered_customer_dt.isna()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- There are orders without \"delivered\" status that have delivery timestamps. Most likely these orders were canceled after delivery."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's examine their reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "messages = (\n",
        "    df_orders[lambda x: (x.order_status != 'Delivered') & ~x.order_delivered_customer_dt.isna()]\n",
        "    .merge(df_reviews, on='order_id', how='left')\n",
        "    ['review_comment_message']\n",
        "    .dropna()\n",
        "    .tolist()\n",
        ")\n",
        "display(messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**\n",
        "\n",
        "- Review messages indicate these orders were not delivered."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Status is \"delivered\" but delivery timestamp is missing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's check if there are orders with \"delivered\" status but missing delivery timestamps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders[lambda x: x.order_status.isin(['Delivered']) & x.order_delivered_customer_dt.isna()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- The dataset contains 8 orders with \"delivered\" status but missing delivery timestamps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's examine their reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "messages = (\n",
        "    df_orders[lambda x: x.order_status.isin(['Delivered']) & x.order_delivered_customer_dt.isna()]\n",
        "    .merge(df_reviews, on='order_id', how='left')\n",
        "    ['review_comment_message']\n",
        "    .dropna()\n",
        "    .tolist()\n",
        ")\n",
        "display(messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Review messages suggest the products were actually delivered."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Order canceled or unavailable but has delivery timestamp**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's check if there are orders with \"canceled\" or \"unavailable\" status that still have delivery timestamps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders[lambda x: x.order_status.isin(['Canceled', 'Unavailable']) & ~x.order_delivered_customer_dt.isna()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- The dataset contains 6 orders with \"canceled\" status that have customer delivery timestamps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's examine their reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "messages = (\n",
        "    df_orders[lambda x: x.order_status.isin(['Canceled', 'Unavailable']) & ~x.order_delivered_customer_dt.isna()]\n",
        "    .merge(df_reviews, on='order_id', how='left')\n",
        "    ['review_comment_message']\n",
        "    .dropna()\n",
        "    .tolist()\n",
        ")\n",
        "display(messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Review messages indicate some items were delivered while others were not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Date Inconsistencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**order_purchase_dt**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's check if there are timestamps earlier than purchase dates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for col_dt in ['order_approved_dt', 'order_delivered_carrier_dt', 'order_delivered_customer_dt']:\n",
        "    rows_cnt = df_orders[~(df_orders['order_purchase_dt'].isna() | df_orders[col_dt].isna()\n",
        "                          | (df_orders['order_purchase_dt'] <= df_orders[col_dt]))].shape[0]\n",
        "    if rows_cnt:\n",
        "        print(f'{col_dt} < order_purchase_dt, rows count: {rows_cnt}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- There are 166 orders where carrier handover time is earlier than purchase time. This is unusual."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's examine the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_mask = ~(df_orders['order_purchase_dt'].isna() | df_orders['order_delivered_carrier_dt'].isna()\n",
        "                          | (df_orders['order_purchase_dt'] <= df_orders['order_delivered_carrier_dt']))\n",
        "tmp_df_orders = df_orders[tmp_mask]\n",
        "print(f'rows: {tmp_df_orders.shape[0]}')\n",
        "display(tmp_df_orders.head(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's analyze by day"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_orders.explore.anomalies_over_time(\n",
        "    time_column='order_purchase_dt'\n",
        "    , custom_mask=tmp_mask\n",
        "    , freq='D'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**\n",
        "- These anomalies only occurred between 25 April and 24 August 2018."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's analyze by order status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders.explore.anomalies_by_categories(\n",
        "    custom_mask=tmp_mask\n",
        "    , pct_diff_threshold=-100\n",
        "    , include_columns='order_status'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at it broken down by payment type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders.explore.anomalies_by_categories(\n",
        "    custom_mask=tmp_mask\n",
        "    , pct_diff_threshold=-100\n",
        "    , include_columns='tmp_payment_types'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**\n",
        "- Over 90% of anomalous orders were paid by credit card."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's analyze by time of day"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders.explore.anomalies_by_categories(\n",
        "    custom_mask=tmp_mask\n",
        "    , pct_diff_threshold=-100\n",
        "    , include_columns='tmp_purchase_time_of_day'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**\n",
        "- Most anomalies occurred in the afternoon."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's examine their reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "messages = (\n",
        "    tmp_df_orders.merge(df_reviews, on='order_id', how='left')\n",
        "    ['review_comment_message']\n",
        "    .dropna()\n",
        "    .sample(20)\n",
        "    .tolist()\n",
        ")\n",
        "display(messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Nothing unusual found."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**order_approved_dt**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's check if there are timestamps that should occur after approval but appear earlier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for col_dt in ['order_delivered_carrier_dt', 'order_delivered_customer_dt']:\n",
        "    rows_cnt = df_orders[~(df_orders['order_approved_dt'].isna() | df_orders[col_dt].isna()\n",
        "                          | (df_orders['order_approved_dt'] <= df_orders[col_dt]))].shape[0]\n",
        "    if rows_cnt:\n",
        "        print(f'{col_dt} < order_approved_dt, rows count: {rows_cnt}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- There are 1,359 orders where carrier handover time is earlier than payment approval time.\n",
        "- There are 61 orders where delivery time is earlier than payment approval time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s examine each one separately."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**order_delivered_carrier_dt < order_approved_dt**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's examine the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_mask = ~(df_orders['order_approved_dt'].isna() | df_orders['order_delivered_carrier_dt'].isna()\n",
        "                          | (df_orders['order_approved_dt'] <= df_orders['order_delivered_carrier_dt']))\n",
        "tmp_df_orders = df_orders[tmp_mask]\n",
        "print(f'rows: {tmp_df_orders.shape[0]}')\n",
        "display(tmp_df_orders.head(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's examine by days"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_orders.explore.anomalies_over_time(\n",
        "    time_column='order_purchase_dt'\n",
        "    , custom_mask=tmp_mask\n",
        "    , freq='D'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**\n",
        "- Days with most anomalies:\n",
        "    - 19-23 April 2018\n",
        "    - 3-4 July 2018\n",
        "- Possible system issues caused delayed payment approvals."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's analyze by order status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders.explore.anomalies_by_categories(\n",
        "    custom_mask=tmp_mask\n",
        "    , pct_diff_threshold=-100\n",
        "    , include_columns='order_status'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**\n",
        "- Nearly all orders were eventually delivered."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's analyze by time of day"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders.explore.anomalies_by_categories(\n",
        "    custom_mask=tmp_mask\n",
        "    , pct_diff_threshold=-100\n",
        "    , include_columns='tmp_purchase_time_of_day'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**\n",
        "- More anomalies occurred in the afternoon."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**order_delivered_customer_dt < order_approved_dt**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_mask = ~(df_orders['order_approved_dt'].isna() | df_orders['order_delivered_customer_dt'].isna()\n",
        "                          | (df_orders['order_approved_dt'] <= df_orders['order_delivered_customer_dt']))\n",
        "tmp_df_orders = df_orders[tmp_mask]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's examine by days"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_orders.explore.anomalies_over_time(\n",
        "    time_column='order_purchase_dt'\n",
        "    , custom_mask=tmp_mask\n",
        "    , freq='D'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**\n",
        "- Anomalies occurred sporadically on specific dates."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at it broken down by payment type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders.explore.anomalies_by_categories(\n",
        "    custom_mask=tmp_mask\n",
        "    , pct_diff_threshold=-100\n",
        "    , include_columns='tmp_payment_types'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**\n",
        "- \"Boleto\" payments had significantly more anomalies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's analyze by customer state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders.explore.anomalies_by_categories(\n",
        "    custom_mask=tmp_mask\n",
        "    , pct_diff_threshold=-100\n",
        "    , include_columns='tmp_customer_state'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**\n",
        "- Most anomalies occurred in São Paulo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**order_delivered_carrier_dt**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's check if there are timestamps that should occur after carrier handover but appear earlier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_mask = ~(df_orders['order_delivered_carrier_dt'].isna() | df_orders['order_delivered_customer_dt'].isna()\n",
        "                        | (df_orders['order_delivered_carrier_dt'] <= df_orders['order_delivered_customer_dt']))\n",
        "rows_cnt = df_orders[tmp_mask].shape[0]\n",
        "if rows_cnt:\n",
        "    print(f'order_delivered_customer_dt < order_delivered_carrier_dt, rows count: {rows_cnt}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- There are 23 orders where delivery time is earlier than carrier handover time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**review_creation_dt < order_purchase_dt**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We have order creation time and review creation time. Let's check if any reviews were created before their corresponding orders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "temp_df = df_orders.merge(df_reviews, on='order_id', how='left')\n",
        "temp_df = temp_df[lambda x: x.order_purchase_dt.dt.date > x.review_creation_dt]\n",
        "temp_df.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The dataset contains 65 orders where reviews were created before the orders themselves."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's examine them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "temp_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at how many orders do not have an approval payment date."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "temp_df.order_approved_dt.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at how many orders do not have a delivery date."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "temp_df.order_approved_dt.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at how many of them were canceled."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "temp_df.order_status.value_counts() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- The dataset contains 65 orders where reviews were created before the orders themselves. 58 orders were canceled. 6 were delivered. 1 was in delivery process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's examine the 6 delivered orders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "temp_df[temp_df.order_status=='Delivered']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We previously determined that one order can have multiple reviews and one review can cover multiple orders.\n",
        "\n",
        "Let's check for duplicates in these orders and reviews."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "temp_unque_orders = temp_df.order_id.unique()\n",
        "temp_unque_reviews = temp_df.review_id.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_reviews[df_reviews.review_id.isin(temp_unque_reviews)].merge(df_orders, on='order_id', how='left').sort_values('review_id').head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Even accounting for duplicates, both orders show review creation dates preceding order dates."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's check if any review responses were created before the reviews themselves:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_reviews[lambda x: x.review_creation_dt >=x.review_answer_dt]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "No such cases found."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  Table df_payments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at the information about the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_payments.explore.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initial Column Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will examine each column individually."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**order_id**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_payments['order_id'].explore.info(plot=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- All is well.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**payment_sequential**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_payments['payment_sequential'].explore.info(plot=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- The maximum number of payment methods for a single order is 29."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**payment_type**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_payments['payment_type'].explore.info(plot=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- 74% of payments were made using credit cards.\n",
        "- The payment_type field contains undefined payment types (<1%)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**payment_installments**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_payments['payment_installments'].explore.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- The maximum number of installments for a product payment is 24.\n",
        "- The median number of payment installments is 1.\n",
        "- 75% of orders have installment plans with 4 or fewer payments.\n",
        "- There are 2 orders with a value of 0 in payment_installments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**payment_value**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_payments['payment_value'].explore.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- There are 9 zero-value payments in payment_value.\n",
        "- The maximum payment is 13.66k. The median payment is 100.\n",
        "- The 13.66k payment is clearly an outlier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exploring Outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_payments.explore.anomalies_report(\n",
        "    anomaly_type='outlier'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's examine payments exceeding 5,000."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_payments[df_payments.payment_value > 5_000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's check for outliers in total order amounts per user."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(\n",
        "    df_customers.merge(df_orders, on='customer_id', how='left')\n",
        "    .merge(df_payments, on='order_id', how='left')\n",
        "    .groupby('customer_unique_id')['payment_value']\n",
        "    .sum()\n",
        "    .sort_values(ascending=False)\n",
        "    .to_frame()\n",
        "    .head(10)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- One user made orders totaling 13,664. This clearly stands out from the rest.\n",
        "- There are also several users who made purchases totaling 6,000 or more."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's identify outliers using quantiles.\n",
        "\n",
        "We'll consider values outside the 5th and 95th percentiles as outliers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_payments.explore.detect_anomalies(\n",
        "    anomaly_type='outlier'\n",
        "    , method='quantile'\n",
        "    , threshold=0.05\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- 10% of payment values are outliers. This exceeds the typical norm (5%) but isn't critical.\n",
        "- For payment installments, outliers account for less than 1%, which is normal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**payment_value**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's examine the distribution of payment value outliers over time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_outl = df_payments.merge(df_orders, on='order_id', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_outl['payment_value'].explore.anomalies_over_time(\n",
        "    time_column='order_purchase_dt'\n",
        "    , anomaly_type='outlier'\n",
        "    , freq='D'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Many payment outliers occurred between November 20-26, 2017, likely related to Black Friday."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "del tmp_outl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exploring Other Anomalies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's explore zero values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_payments.explore.anomalies_report(\n",
        "    anomaly_type='zero'\n",
        "    , sample_size=20\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Orders with zero payment amounts have either \"voucher\" or \"not_defined\" as their payment type."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's examine zeros in each column separately."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Zeros in payment_installments**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_payments[df_payments.payment_installments == 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since payment_sequential shows 2, there should have been another payment. Let's examine these orders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_payments[df_payments.order_id == '744bade1fcf9ff3f31d860ace076d422']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_payments[df_payments.order_id == '1a57108394169c0b47d8f876acc9ba2d']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's check these orders in df_items."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_items[df_items.order_id == '744bade1fcf9ff3f31d860ace076d422']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_items[df_items.order_id == '1a57108394169c0b47d8f876acc9ba2d']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we can see, the order wasn't fully recorded in df_payments. The first payment is missing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Zeros in payment_value**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_payments[df_payments.payment_value == 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's look at other payments for order fa65dad1b0e818e3ccc5cb0e39231352."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_payments[df_payments.order_id == '8bcbe01d44d147f901cd3192671144db']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- One payment was processed as zero, and it was the last payment.- \n",
        "- Moreover, all zero payments have either \"voucher\" or \"not_defined\" as their type.- \n",
        "- There might be some specific payment logic here.- \n",
        "- It's better not to modify these zeros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  Table df_items"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at the information about the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_items.explore.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initial Column Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will examine each column individually."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**order_id**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_items['order_id'].explore.info(plot=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**order_item_id**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_items['order_item_id'].explore.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- The maximum quantity of items in a single order is 21.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**product_id**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_items['product_id'].explore.info(plot=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**seller_id**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_items['seller_id'].explore.info(plot=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**shipping_limit_dt**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_items['shipping_limit_dt'].explore.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- In shipping_limit_dt: 20% missing years, 41% missing months, 47% missing weeks, 57% missing days.\n",
        "- The maximum date in shipping_limit_dt is 2020-04-09.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**price**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_items['price'].explore.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Most products are priced between 39.9 and 134.9.\n",
        "- The median product price is 74.99."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**freight_value**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_items['freight_value'].explore.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- There are zero values in freight_value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exploring Outliers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_items.explore.anomalies_report(\n",
        "    anomaly_type='outlier'\n",
        "    , exclude_columns='seller_id'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- About 10% outliers exist in product prices and shipping costs. This exceeds the typical norm (usually 5%) but isn't critical."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Product Sales Inconsistencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checking if any products in the items table have multiple sellers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_items.groupby('product_id')['seller_id'].nunique().sort_values(ascending=False).head(10).to_frame('sellers_cnt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Some product IDs were sold by different sellers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_items.groupby('product_id')['seller_id'].nunique().value_counts().to_frame('products_cnt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Over 1,000 products have more than 2 sellers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Examining product d285360f29ac7fd97640bf0baef03de0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_products[lambda x: x.product_id == 'd285360f29ac7fd97640bf0baef03de0']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_res = (df_items[lambda x: x.product_id == 'd285360f29ac7fd97640bf0baef03de0']\n",
        "        [['shipping_limit_dt', 'price', 'freight_value', 'seller_id']]\n",
        "        .merge(df_sellers, on='seller_id', how='left')\n",
        ")\n",
        "tmp_df_res.seller_id.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_res.seller_state.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_res.seller_city.unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Sellers are located in different cities.\n",
        "- This might not be an anomaly - different sellers could legitimately sell identical products with matching IDs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checking if any products were sold across different seller states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(df_items.merge(df_sellers, on='seller_id', how='left')\n",
        " .groupby('product_id')['seller_state'].nunique().sort_values(ascending=False).head(10).to_frame('states_cnt')\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Some products were sold by sellers in different states."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Verifying city consistency for customer_id in the customers table (as this is our join key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(df_customers.groupby('customer_id')[['customer_state', 'customer_city']].nunique() > 1).sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "All is well.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Date Inconsistencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**shipping_limit_dt**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Analyzing anomalous shipping_limit_dt values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_items[df_items.shipping_limit_dt > '2018-12-31'].merge(df_orders, on='order_id', how='left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Found 4 orders with abnormally large shipping_limit_dt values, despite having normal estimated delivery times."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exploring Other Anomalies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Examining zero values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_zeros = df_items.explore.detect_anomalies(\n",
        "    anomaly_type='zero'\n",
        "    , return_mode='by_column'\n",
        ")['freight_value']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Zero freight values may indicate free shipping."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Examing rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_zeros.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reviewing zero-value over time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_items.freight_value.explore.anomalies_over_time(\n",
        "    time_column='shipping_limit_dt'\n",
        "    , anomaly_type='zero'\n",
        "    , freq='W'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Most zero shipping costs occurred between April-July 2018."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  Table df_customers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at the information about the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_customers.explore.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initial Column Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will examine each column individually."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**customer_id**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_customers['customer_id'].explore.info(plot=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**customer_unique_id**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_customers['customer_unique_id'].explore.info(plot=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- customer_unique_id has 3% duplicates - acceptable as this field doesn't require uniqueness in this table.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**customer_zip_code_prefix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_customers['customer_zip_code_prefix'].explore.info(plot=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**customer_city**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_customers['customer_city'].explore.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Most customers are from São Paulo city (16%).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**customer_state**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_customers['customer_state'].explore.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Most customers are from SP state (42%).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  Table df_reviews"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at the information about the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_reviews.explore.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initial Column Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will examine each column individually."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**review_id**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_reviews['review_id'].explore.info(plot=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- review_id contains 827 duplicates.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**order_id**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_reviews['order_id'].explore.info(plot=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- order_reviews table has 559 duplicate order_ids.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**review_score**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_reviews['review_score'].explore.info(column_type='categorical')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Over half of reviews (57%) give maximum 5-star ratings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**review_comment_title**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_reviews['review_comment_title'].explore.info(column_type='text')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- 88% of review titles are missing.\n",
        "- Most common review title (8%) is 'recomendo'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**review_comment_message**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_reviews['review_comment_message'].explore.info() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- 58% of orders lack review messages.\n",
        "- Only 36% of review comments are unique.\n",
        "- Most frequent comment (1%) contains \"muito bom\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**review_creation_dt**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_reviews['review_creation_dt'].explore.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- review_creation_dt has 9% missing days."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**review_answer_dt**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_reviews['review_answer_dt'].explore.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- review_answer_dt has 5% missing days."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exploring Missing Values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checking columns with missing values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_reviews.explore.anomalies_report(\n",
        "    anomaly_type='missing'\n",
        "    , pct_diff_threshold=10\n",
        "    , show_by_categories=False\n",
        "    , show_sample=False\n",
        "    , width=600\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Missing review titles/messages aren't anomalies - they were simply not provided."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exploring Duplicates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Examining duplicates in order_id and review_id:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_reviews[['order_id', 'review_id']].duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "No instances where both order_id and review_id are duplicated simultaneously."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Theoretical possibility: one order could have multiple reviews, but multiple orders sharing one review is unusual."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Analyzing order_id and review_id duplicates separately"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**review_id**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_dupl = df_reviews[df_reviews.review_id.duplicated()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reviewing review_id duplicate distribution over time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_reviews.review_id.explore.anomalies_over_time(\n",
        "    time_column='review_creation_dt'\n",
        "    , anomaly_type='duplicate'\n",
        "    , freq='W'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- March 2018 saw a significant spike in duplicate review_ids (one review applied to multiple orders)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checking for duplicates with different customers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_dupl = (\n",
        "    tmp_dupl.merge(df_orders, on='order_id', how='left')\n",
        "    .merge(df_customers, on='customer_id', how='left')\n",
        ")\n",
        "tmp_dupl.groupby('review_id')['customer_unique_id'].nunique().value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- No duplicates with different customers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Examining product quantities in these orders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(\n",
        "    tmp_dupl.merge(df_items, on='order_id', how='left')\n",
        "    .groupby('order_id')['product_id']\n",
        "    .nunique()\n",
        "    .value_counts()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Most orders contain one product.\n",
        "- Some orders show no products (due to missing records in the items table)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_dupl = (tmp_dupl.merge(df_payments, on='order_id', how='left')\n",
        "            .merge(df_items, on='order_id', how='left')\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_dupl = tmp_dupl[['review_id', 'order_id', 'review_score', 'review_comment_title', 'review_comment_message'\n",
        "                   , 'review_creation_dt', 'order_delivered_customer_dt', 'order_status', 'payment_type'\n",
        "                   , 'payment_value', 'product_id', 'price', 'freight_value']].sort_values('review_id').drop_duplicates()\n",
        "tmp_dupl.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Comparing duplicate values across columns (replacing missing values with __na__):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(tmp_dupl.fillna({'review_comment_message': '__na__'})\n",
        " .groupby('review_id')\n",
        " [['review_comment_message', 'review_score', 'order_status', 'payment_type', 'payment_value', 'product_id', 'price']]\n",
        " .nunique()\n",
        " .apply(pd.Series.value_counts)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Identical reviews were left for different orders with matching ratings and descriptions, but varying products/prices.- \n",
        "- This is unusual - could indicate bulk reviews for multiple orders or data collection errors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**order_id**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Analyzing order_id duplicate distribution over time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_dupl = df_reviews[df_reviews.order_id.duplicated()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_reviews.order_id.explore.anomalies_over_time(\n",
        "    time_column='review_creation_dt'\n",
        "    , anomaly_type='duplicate'\n",
        "    , freq='W'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- March 2018 showed a spike in order_id duplicates (multiple reviews for single orders)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_dupl = (tmp_dupl.merge(df_orders, on='order_id', how='left')\n",
        "            .merge(df_customers, on='customer_id', how='left')\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_dupl = tmp_dupl[['order_id', 'review_id', 'review_score', 'review_comment_title', 'review_comment_message'\n",
        "                   , 'review_creation_dt', 'order_delivered_customer_dt', 'order_status']].sort_values('order_id').drop_duplicates()\n",
        "tmp_dupl.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Customers sometimes left multiple reviews per order (e.g., one pre-delivery and one post-delivery) - not necessarily anomalous."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's examine how many duplicates share identical values across different columns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For description fields, we'll replace missing values with __na__."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(tmp_dupl.fillna({'review_comment_message': '__na__'})\n",
        " .groupby('order_id')\n",
        " [['review_comment_message', 'review_score', 'order_status']]\n",
        " .nunique()\n",
        " .apply(pd.Series.value_counts)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Secondary Review Rating Comparison\n",
        "\n",
        "We'll analyze whether follow-up reviews for the same order had higher or lower ratings:\n",
        "\n",
        "- Compare average ratings with initial ratings\n",
        "- If initial rating was lower, subsequent ratings were either equal or higher"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(tmp_dupl.sort_values(['order_id', 'review_creation_dt'])\n",
        " .groupby('order_id')\n",
        " .agg(\n",
        "     first_review_score = ('review_score', 'first')\n",
        "     , mean_review_score = ('review_score', 'mean')\n",
        " )\n",
        " .assign(\n",
        "     is_first_less_mean = lambda x: x.first_review_score < x.mean_review_score\n",
        " )\n",
        " ['is_first_less_mean']\n",
        " .value_counts()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Subsequent reviews for the same order typically received lower ratings than the initial review."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "del tmp_dupl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  Table df_products"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at the information about the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_products.explore.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initial Column Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will examine each column individually."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**product_id**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_products['product_id'].explore.info(plot=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**product_category_name**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_products['product_category_name'].explore.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- product_category_name contains 2% missing values\n",
        "- Dataset contains 73 unique product categories"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**product_name_lenght**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_products['product_name_lenght'].explore.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- product_name_lenght has 2% missing values\n",
        "- Maximum product name length: 76 characters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**product_description_lenght**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_products['product_description_lenght'].explore.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- There are 2% missing values in product_description_lenght.\n",
        "- The maximum length of the product description is 3.99k characters.\n",
        "- The minimum length of the product description is 4 characters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**product_photos_qty**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_products['product_photos_qty'].explore.info(column_type='categorical')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- In product_photos_qty, 2% of values are missing.\n",
        "- The maximum number of photos for a single product is 20.\n",
        "- 50% of products have 1 photo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**product_weight_g**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_products['product_weight_g'].explore.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- In product_weight_g, there are 2 missing values.\n",
        "- In product_weight_g, there are 4 zero values.\n",
        "- The maximum product weight is 40.42k grams.\n",
        "- The product weight of 40.42k grams is clearly an outlier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**product_length_cm**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_products['product_length_cm'].explore.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- In product_length_cm, there are 2 missing values.\n",
        "- The maximum product length is 105 cm. The minimum is 7 cm. The median is 25 cm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**product_height_cm**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_products['product_height_cm'].explore.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- In product_height_cm, there are 2 missing values.\n",
        "- The maximum product height is 105 cm. The minimum is 2 cm. The median is 13 cm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**product_width_cm**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_products['product_width_cm'].explore.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- In product_width_cm, there are 2 missing values.\n",
        "- The maximum product width is 118 cm. The minimum is 6 cm. The median is 20 cm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exploring Missing Values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's see which columns have missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_products.explore.anomalies_report(\n",
        "    anomaly_type='missing'\n",
        "    , pct_diff_threshold=10\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's hypothesize that missing values in the following columns are in the same rows:\n",
        "\n",
        "- product category name\n",
        "- product name length\n",
        "- product description length\n",
        "- number of product photos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_products.explore.detect_simultaneous_anomalies(['product_category_name', 'product_name_lenght', 'product_description_lenght', 'product_photos_qty'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Missing values in product category name, product name length, product description length, and number of product photos are in the same rows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's hypothesize that missing values in the following columns are in the same rows:\n",
        "\n",
        "- product length\n",
        "- product width\n",
        "- product height\n",
        "- product weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_products.explore.detect_simultaneous_anomalies(['product_weight_g', 'product_length_cm', 'product_height_cm', 'product_width_cm'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Missing values in product length, width, height, and weight are located in the same rows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exploring Outliers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_products.explore.anomalies_report(\n",
        "    anomaly_type='outlier'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- The proportion of outliers in the number of photos, length, and width of products is within normal limits.\n",
        "- The proportion of outliers in product weight and height exceeds the norm (usually 5%), but is not critical."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exploring Other Anomalies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Examining zero values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_products.explore.anomalies_report(\n",
        "    anomaly_type='zero'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- All 4 products with zero weight belong to the category cama_mesa_banho (home textiles)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  Table df_categories"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at the information about the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_categories.explore.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initial Column Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will examine each column individually."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**product_category_name**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_categories['product_category_name'].explore.info(plot=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- The product_category_name table has 71 unique product categories, while the products table has 73 categories."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**product_category_name_english**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_categories['product_category_name_english'].explore.info(plot=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  Table df_sellers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at the information about the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sellers.explore.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initial Column Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will examine each column individually."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**seller_id**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sellers['seller_id'].explore.info(plot=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**seller_zip_code_prefix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sellers['seller_zip_code_prefix'].explore.info(plot=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**seller_city**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sellers['seller_city'].explore.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- The most sellers are from the city of sao paulo (22%).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-26T04:37:06.989215Z",
          "iopub.status.busy": "2025-07-26T04:37:06.988901Z",
          "iopub.status.idle": "2025-07-26T04:37:07.231153Z",
          "shell.execute_reply": "2025-07-26T04:37:07.229735Z"
        }
      },
      "source": [
        "**seller_state**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sellers['seller_state'].explore.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- The most sellers are from the state of sp (60%).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  Table df_geolocations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at the information about the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_geolocations.explore.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- The df_geolocations table has 28% fully duplicated rows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initial Column Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will examine each column individually."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**geolocation_zip_code_prefix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_geolocations['geolocation_zip_code_prefix'].explore.info(plot=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**geolocation_lat**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_geolocations['geolocation_lat'].explore.info(plot=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**geolocation_lng**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_geolocations['geolocation_lng'].explore.info(plot=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**geolocation_city**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_geolocations['geolocation_city'].explore.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- In geolocation_city, the most entries are for the city of sao paulo (16%).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**geolocation_state**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_geolocations['geolocation_state'].explore.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- In geolocation_state, the most entries are for the state of SP (40%).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exploring Duplicates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We have complete row duplicates in the geolocation table. Let's examine them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's check if we have duplicates in the geolocation table in the geolocation_zip_code_prefix field, excluding common duplicates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_geo = df_geolocations.drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_geo.explore.detect_anomalies('duplicate', columns=['geolocation_zip_code_prefix'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- In the df_geolocations table, there are 97% duplicates in the geolocation_zip_code_prefix column."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's see why there are duplicates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_geo.groupby('geolocation_zip_code_prefix').nunique().head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This makes sense, as geolocation_zip_code_prefix can have many different unique coordinates.\n",
        "\n",
        "But we need to take this into account when joining tables, since we only have zip_code_prefix in the customer and seller tables.\n",
        "\n",
        "When joining, we may get many duplicates."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can average the coordinates, but we can't do the same with cities and states."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's check if we have multiple states for a single prefix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_geo.groupby('geolocation_zip_code_prefix').geolocation_state.nunique().sort_values(ascending=False).head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's see the maximum number of cities with the same prefix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_geo.groupby('geolocation_zip_code_prefix').geolocation_city.nunique().sort_values(ascending=False).head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- In the df_geolocations table, there are prefixes with 2 unique states.\n",
        "- In the df_geolocations table, there are prefixes with 4 unique cities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There's nothing we can do about this. We'll need to account for this when analyzing geolocation coordinates.\n",
        "\n",
        "Since we have states in the customer and seller tables, we can avoid using city and state from the geolocation table.\n",
        "\n",
        "And we can average the coordinates."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exploring Outliers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's see how many sales we have outside South America."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_geo = df_geolocations.copy()\n",
        "tmp_geo['in_south_america'] = (\n",
        "    (tmp_geo.geolocation_lat >= -53.90) &  # Southern border\n",
        "    (tmp_geo.geolocation_lat <= 12.45) &   # Northern border\n",
        "    (tmp_geo.geolocation_lng >= -81.32) &  # Western border\n",
        "    (tmp_geo.geolocation_lng <= -34.79)    # Eastern border\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "temp_df = (df_orders[['order_id', 'customer_id']].merge(df_customers, on='customer_id', how='left')\n",
        "              .merge(tmp_geo.drop_duplicates(subset=[\"geolocation_zip_code_prefix\"]), left_on='customer_zip_code_prefix', right_on='geolocation_zip_code_prefix', how='left')\n",
        "              .dropna()\n",
        "              [['in_south_america', 'customer_city', 'customer_state', 'geolocation_lat', 'geolocation_lng']]\n",
        ")\n",
        "temp_df.in_south_america.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- There are 6 sales outside South America in the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's look at these orders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "temp_df[temp_df.in_south_america == False]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These coordinates are outside South America.\n",
        "Either it's an error, or the order was placed outside South America.\n",
        "\n",
        "- (42.18, -8.72) is off the coast of Spain/Portugal\n",
        "- (20.09, -30.54) is in the central Atlantic Ocean\n",
        "- (13.00, -23.58) is in the eastern Atlantic Ocean near Cape Verde\n",
        "- (-11.31, -34.73) is in the South Atlantic\n",
        "- (20.09, -30.54) is a repeating point in the central Atlantic Ocean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "del temp_df, tmp_geo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exploring Cross-Table Anomalies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Temporal Boundary Checks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Examining time interval boundaries across different tables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for key, df in dfs:\n",
        "    datetime_cols = [col for col in df.columns if pd.api.types.is_datetime64_any_dtype(df[col])]\n",
        "    for col in datetime_cols:\n",
        "        min_date = df[col].min()\n",
        "        max_date = df[col].max()    \n",
        "        print(f\"[{min_date.date()} - {max_date.date()}] DataFrame '{key}', Column '{col}':\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- The latest date in order_approved_dt is earlier than in order_purchase_dt.- \n",
        "- Anomalously large maximum date in shipping_limit_dt compared to other temporal variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Payment-Order Amount Mismatches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checking for orders where payment total differs from order value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "temp_df = (\n",
        "    df_items[['order_id', 'price', 'freight_value']]\n",
        "    .groupby('order_id')\n",
        "    .sum()\n",
        "    .assign(total_price=lambda x: x['price'] + x['freight_value'])\n",
        "    .drop(columns=['price', 'freight_value'])\n",
        "    .reset_index()\n",
        "    .merge(df_payments, on='order_id', how='inner')\n",
        "    .merge(df_orders, on='order_id', how='inner')\n",
        "    .dropna(subset=['payment_value', 'total_price'])\n",
        ")\n",
        "temp_df['payment_matches_total'] = temp_df['payment_value'].round(2) == temp_df['total_price'].round(2)\n",
        "temp_df['payment_matches_total'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Dataset contains 7,877 orders with payment-amount discrepancies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_mask = ~temp_df.payment_matches_total"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's analyze by payment type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "temp_df.explore.anomalies_by_categories(\n",
        "    custom_mask=tmp_mask\n",
        "    , pct_diff_threshold=-100\n",
        "    , include_columns='tmp_payment_types'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Payment type analysis shows most mismatches involve voucher payments (likely systemic issue)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exploring Relationships Between Tables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reviewing inter-table connections for future joins and key consistency."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**df_orders and df_payments**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fron.analyze_join_keys(df_orders, df_payments, \"order_id\", short_result=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Orders table contains 1 order_id missing from payments table."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's look at what this order is."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "temp_df = df_orders.merge(df_payments, on='order_id', how='left')\n",
        "temp_df[temp_df.payment_value.isna()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**df_orders and df_items**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fron.analyze_join_keys(df_orders, df_items, \"order_id\", short_result=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- Orders table contains 775 order_ids missing from items table."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We have a payments table. Let's check if orders missing from items exist in payments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "missing_orders = (df_orders.merge(df_items, on='order_id', how='left')\n",
        "                  [lambda x: x['order_item_id'].isna()].order_id.unique()\n",
        ")\n",
        "len(missing_orders)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_payments[df_payments.order_id.isin(missing_orders)].order_id.nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "All these orders are present in the payments table."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's check how many of these orders are canceled."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders[df_orders['order_id'].isin(missing_orders)].order_status.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- These orders are either canceled, unavailable, or just created."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's examine orders with \"shipped\" status."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders[df_orders['order_id'].isin(missing_orders) & (df_orders.order_status == 'Shipped')]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**df_orders and df_customers**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fron.analyze_join_keys(df_orders, df_customers, \"customer_id\", short_result=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- All is well.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**df_orders and df_reviews**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fron.analyze_join_keys(df_orders, df_reviews, \"order_id\", short_result=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- All is well.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**df_items and df_products**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fron.analyze_join_keys(df_items, df_products, \"product_id\", short_result=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- All is well.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**df_items and df_sellers**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fron.analyze_join_keys(df_items, df_sellers, \"seller_id\", short_result=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- All is well.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**df_customers and df_geolocations**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fron.analyze_join_keys(df_customers, df_geolocations, left_on = 'customer_zip_code_prefix', right_on = \"geolocation_zip_code_prefix\", short_result=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- In df_customers table, there are 157 zip_code_prefixes not present in df_geolocations.- \n",
        "- In df_geolocations table, there are 4178 zip_code_prefixes not present in df_customers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**df_sellers and df_geolocations**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fron.analyze_join_keys(df_sellers, df_geolocations, left_on = 'seller_zip_code_prefix', right_on = \"geolocation_zip_code_prefix\", short_result=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**  \n",
        "\n",
        "- In df_sellers table, there are 7 zip_code_prefixes not present in df_geolocations.- \n",
        "- In df_geolocations table, there are 16776 zip_code_prefixes not present in df_sellers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Delete temporary fields."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders = df_orders[[col for col in df_orders.columns if not col.startswith('tmp_')]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Clear memory of temporary variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for var_name in list(globals().keys()):\n",
        "    if var_name.startswith('tmp_'):\n",
        "        del globals()[var_name]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "remove-cell"
        ]
      },
      "source": [
        "%run ../../_post_run.ipynb"
      ],
      "outputs": []
    }
  ]
}