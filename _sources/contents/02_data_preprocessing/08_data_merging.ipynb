{
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 4,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "remove-cell"
        ]
      },
      "source": [
        "%run ../../_pre_run.ipynb"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Merging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Enriching Table df_items"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Buyer-Seller Distance**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create a distance variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_customers = df_customers.merge(df_geolocations, left_on='customer_zip_code_prefix', right_on='geolocation_zip_code_prefix', how='left')\n",
        "tmp_df_customers.rename(columns={'geolocation_lat': 'lat_customer', 'geolocation_lng': 'lng_customer'}, inplace=True)\n",
        "tmp_df_customers.drop(['geolocation_zip_code_prefix', 'geolocation_zip_code_prefix_3_digits'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "tmp_df_sellers = df_sellers.merge(df_geolocations, left_on='seller_zip_code_prefix', right_on='geolocation_zip_code_prefix', how='left')\n",
        "tmp_df_sellers.rename(columns={'geolocation_lat': 'lat_seller', 'geolocation_lng': 'lng_seller'}, inplace=True)\n",
        "tmp_df_sellers.drop(['geolocation_zip_code_prefix', 'geolocation_zip_code_prefix_3_digits'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_items = (\n",
        "    df_items.merge(df_orders[['order_id', 'customer_id']], on='order_id', how='left')\n",
        "    .merge(tmp_df_customers[['customer_id', 'lat_customer', 'lng_customer']], on='customer_id', how='left')\n",
        "    .merge(tmp_df_sellers[['seller_id', 'lat_seller', 'lng_seller']], on='seller_id', how='left')\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calculate buyer-seller distances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_items['distance_km'] = fron.haversine_vectorized(\n",
        "    df_items['lat_customer'].values,\n",
        "    df_items['lng_customer'].values,\n",
        "    df_items['lat_seller'].values,\n",
        "    df_items['lng_seller'].values\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_items.drop(['customer_id', 'lat_customer', 'lng_customer', 'lat_seller', 'lng_seller'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check for missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_items.distance_km.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Missing values occur when zip prefixes are absent from the geolocation table for some buyers/sellers.\n",
        "\n",
        "The quantity is small - leave as is."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Carrier Handoff Delay**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create a carrier handoff delay variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_items = df_items.merge(df_orders[['order_id', 'order_delivered_carrier_dt']], on='order_id', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_items['carrier_delivery_delay_days'] = df_items['order_delivered_carrier_dt'] - df_items['shipping_limit_dt']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Convert to days.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_items['carrier_delivery_delay_days'] = df_items['carrier_delivery_delay_days'].dt.total_seconds() / (24 * 3600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_items.drop(['order_delivered_carrier_dt'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Enriching Table df_orders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### From Table  df_payments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create these order-level metrics:\n",
        "\n",
        "- Payment count\n",
        "- Payment sum\n",
        "- Average payment\n",
        "- Total installment count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create these order-level dimensions:\n",
        "\n",
        "- Installment presence\n",
        "- Payment types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_pay_agg = df_payments.copy()\n",
        "tmp_df_pay_agg['has_installments'] = tmp_df_pay_agg['has_installments'] == 'Has Installments'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Examine unique payment types per order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_pay_agg.groupby('order_id')['payment_type'].nunique().value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since maximum is 2 payment types, concatenate them during aggregation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_pay_agg = (\n",
        "    tmp_df_pay_agg.groupby('order_id', as_index=False)\n",
        "    .agg(\n",
        "        payments_cnt = ('payment_sequential', 'count')\n",
        "        , total_payment = ('payment_value', 'sum')\n",
        "        , avg_payment = ('payment_value', 'mean')\n",
        "        , total_installments_cnt = ('payment_installments', 'sum')\n",
        "        , order_has_installment = ('has_installments', 'any')\n",
        "        , order_payment_types = ('payment_type', lambda x: ', '.join(sorted(set(x))))\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_pay_agg['order_payment_types'] = tmp_df_pay_agg['order_payment_types'].astype('category')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_pay_agg['order_has_installment'] = tmp_df_pay_agg.order_has_installment.map({True: 'Has Installments', False: 'No Installments'}).astype('category')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Merge with df_orders."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check key mismatches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fron.analyze_join_keys(df_orders, tmp_df_pay_agg, \"order_id\", how='left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Merge tables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders = df_orders.merge(tmp_df_pay_agg, on='order_id', how='left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### From Tables df_items and df_products"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create these order-level metrics:\n",
        "\n",
        "- Total product count\n",
        "- Unique product count\n",
        "- Seller count\n",
        "- Unique category count\n",
        "- Total product price\n",
        "- Average product price\n",
        "- Total shipping cost\n",
        "- Total order value\n",
        "- Shipping cost ratio\n",
        "- Order weight\n",
        "- Order volume\n",
        "- Average buyer-seller distance\n",
        "- Average carrier handoff delay"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create these order-level dimensions:\n",
        "\n",
        "- Free shipping indicator\n",
        "- Generalized product categories"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First merge items and products tables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check key mismatches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fron.analyze_join_keys(df_items, df_products, \"product_id\", how='left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Merge tables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_items_prods = df_items.merge(df_products, on='product_id', how='left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prepare dataframe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Examine unique categories per order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_items_prods.groupby('order_id')['product_category'].nunique().value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Maximum 3 categories - concatenate during aggregation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Examine unique generalized categories per order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_items_prods.groupby('order_id')['general_product_category'].nunique().value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Maximum 3 categories - concatenate during aggregation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_items_prods_agg = (tmp_df_items_prods.groupby('order_id', as_index=False)\n",
        "          .agg(\n",
        "              products_cnt = ('product_id', 'count')\n",
        "              , unique_products_cnt = ('product_id', 'nunique')\n",
        "              , sellers_cnt = ('seller_id', 'nunique')\n",
        "              , product_categories_cnt = ('product_category', 'nunique')\n",
        "              , total_products_price = ('price', 'sum')\n",
        "              , avg_products_price = ('price', 'mean')\n",
        "              , total_freight_value = ('freight_value', 'sum')\n",
        "              , total_order_price = ('total_price', 'sum')\n",
        "              , total_weight_kg = ('product_weight_g', 'sum')\n",
        "              , total_volume_cm3 = ('product_volume_cm3', 'sum')\n",
        "              , avg_distance_km = ('distance_km', 'mean')\n",
        "              , avg_carrier_delivery_delay_days = ('carrier_delivery_delay_days', 'mean')\n",
        "              , order_product_categories = ('product_category', lambda x: ', '.join(sorted(set(x))))\n",
        "              , order_general_product_categories = ('general_product_category', lambda x: ', '.join(sorted(set(x))))\n",
        "          )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_items_prods_agg['freight_ratio'] = tmp_df_items_prods_agg['total_freight_value'] / tmp_df_items_prods_agg['total_order_price']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_items_prods_agg['order_product_categories'] = tmp_df_items_prods_agg['order_product_categories'].astype('category')\n",
        "tmp_df_items_prods_agg['order_general_product_categories'] = tmp_df_items_prods_agg['order_general_product_categories'].astype('category')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_items_prods_agg['total_weight_kg'] = (tmp_df_items_prods_agg['total_weight_kg'] / 1000).round(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_items_prods_agg['order_is_free_shipping'] = tmp_df_items_prods_agg.total_freight_value == 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_items_prods_agg['order_is_free_shipping'] = tmp_df_items_prods_agg.order_is_free_shipping.map({True: 'Free Shipping', False: 'Paid Shipping'}).astype('category')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_items_prods_agg['order_is_free_shipping'].value_counts(dropna=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Add new fields to df_orders."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check key mismatches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fron.analyze_join_keys(df_orders, tmp_df_items_prods_agg, \"order_id\", how='left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We previously identified orders in df_orders missing from df_items.\n",
        "\n",
        "These are all either canceled or unavailable - missing values from items table are expected."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Merge tables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders = df_orders.merge(tmp_df_items_prods_agg, on='order_id', how='left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### From Table  df_customers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Add customer city and state."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check key mismatches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fron.analyze_join_keys(df_orders, df_customers, \"customer_id\", how='left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Add fields to df_orders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders = df_orders.merge(df_customers[['customer_id', 'customer_unique_id', 'customer_state', 'customer_city']], on='customer_id', how='left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### From Table  df_reviews"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create these order-level metrics:\n",
        "\n",
        "- Review count\n",
        "- Average review score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_reviews_agg = (\n",
        "    df_reviews.groupby('order_id', as_index=False)\n",
        "    .agg(\n",
        "        reviews_cnt = ('review_id', 'nunique')\n",
        "        , order_avg_reviews_score = ('review_score', 'mean')\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since secondary reviews tend to be lower-scored, round down."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_reviews_agg['order_avg_reviews_score'] = np.floor(tmp_df_reviews_agg['order_avg_reviews_score']).astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check key mismatches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fron.analyze_join_keys(df_orders, tmp_df_reviews_agg, \"order_id\", how='left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Add fields to df_orders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders = df_orders.merge(tmp_df_reviews_agg, on='order_id', how='left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating New Dimensions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Create a new payment amount dimension**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at the quantiles in the column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders.total_payment.quantile([0.05, 0.25, 0.5, 0.75, 0.95])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create the following categories:\n",
        "\n",
        "- Cheap: ≤50 R$\n",
        "- Medium: 50-200 R$\n",
        "- Expensive: >200 R$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = ['Cheap', 'Medium', 'Expensive']\n",
        "bins = [-np.inf, 50, 200, np.inf]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders['order_total_payment_cat'] = df_orders.total_payment.preproc.to_categorical(method='custom_bins', labels=labels, bins=bins)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Create a new order weight dimension**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at the quantiles in the column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders.total_weight_kg.quantile([0.05, 0.25, 0.5, 0.75, 0.95])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Categories for order weight:\n",
        "\n",
        "- Light: ≤500g\n",
        "- Medium: 500-5000g\n",
        "- Heavy: >5kg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = ['Light', 'Medium', 'Heavy']\n",
        "bins = [-np.inf, 0.5, 5, np.inf]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders['order_total_weight_cat'] = (\n",
        "    df_orders.total_weight_kg.preproc\n",
        "    .to_categorical(method='custom_bins', labels=labels, bins=bins, fill_na_value='Missing in Items')\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Create a new order volume dimension**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at the quantiles in the column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders.total_volume_cm3.quantile([0.05, 0.25, 0.5, 0.75, 0.95])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Categories for order volume:\n",
        "\n",
        "- Small: ≤3500 cm3\n",
        "- Medium: 3500-10000 cm3\n",
        "- Large: >10000 cm3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = ['Small', 'Medium', 'Large']\n",
        "bins = [-np.inf, 3500, 10000, np.inf]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders['order_total_volume_cat'] = (\n",
        "    df_orders.total_volume_cm3.preproc\n",
        "    .to_categorical(method='custom_bins', labels=labels, bins=bins, fill_na_value='Missing in Items')\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Create a new review score dimension**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Categories:\n",
        "\n",
        "- Positive: 4-5\n",
        "- Neutral: 3\n",
        "- Negative: 1-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rules = {\n",
        "    \"Positive\": lambda x: x.isin([4, 5]),\n",
        "    \"Neutral\": lambda x: x == 3,\n",
        "    'Negative': lambda x: x.isin([1, 2]),\n",
        "    \"Missing Score\": \"default\"\n",
        "}\n",
        "df_orders['order_review_sentiment'] = df_orders.order_avg_reviews_score.preproc.to_categorical(rules=rules)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at the missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders.explore.detect_anomalies()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Missing values in time-related variables occur due to absent dates (normal for undelivered orders)\n",
        "- Missing values in product-related variables occur because some orders aren't in the items table (canceled/unavailable). These won't affect sales analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For dimensions, replace missing values with 'No Order In Items'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders['order_product_categories'] = df_orders['order_product_categories'].cat.add_categories('No Order in Items').fillna('No Order in Items')\n",
        "df_orders['order_general_product_categories'] = df_orders['order_general_product_categories'].cat.add_categories('No Order in Items').fillna('No Order in Items')\n",
        "df_orders['order_is_free_shipping'] = df_orders['order_is_free_shipping'].cat.add_categories('No Order in Items').fillna('No Order in Items')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating Table df_sales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The orders table contains order creation time, payment approval time, and order status. After examining statuses:\n",
        "\n",
        "- **created**: Few orders, old, comments indicate non-delivery\n",
        "- **approved**: Few orders, old, no comments\n",
        "- **processing**: >90% have 1-2 star reviews, most undelivered (some reviews mention stockouts)\n",
        "- **invoiced**: >80% have 1-2 stars, mostly undelivered (some mention stockouts)\n",
        "- **shipped**: >70% have 1-2 stars, mostly undelivered"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's look at how the total delivery time is distributed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders.viz.histogram(\n",
        "    x='delivery_time_estimated_days'\n",
        "    , labels={'delivery_time_estimated_days': 'Delivery time to customer, days'}\n",
        "    , title='Distribution of delivery time to customer'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Delivery typically takes ≤1 month. We'll use this threshold to determine delivery status."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's look at how the statuses are distributed for orders that have passed a month from the estimated delivery date."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_last_date = df_orders.order_purchase_dt.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_mask = lambda x: ((tmp_last_date - x.order_estimated_delivery_dt).dt.days > 31) & (x.order_status != 'Delivered')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders[tmp_mask].order_status.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations:**\n",
        "\n",
        "- Since delivery usually takes ≤1 month, orders exceeding this are considered undelivered (confirmed by review content mentioning non-delivery/stockouts)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We'll define a purchase as:\n",
        "\n",
        "- Orders without 'canceled'/'unavailable' status\n",
        "- Orders with 'delivered' status\n",
        "- Orders without 'delivered' status where <31 days since purchase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_mask = (\n",
        "    (df_orders.order_status == 'Delivered') |\n",
        "    (\n",
        "        ((tmp_last_date - df_orders.order_estimated_delivery_dt).dt.days <= 31) & \n",
        "        (~df_orders.order_status.isin(['Canceled', 'Unavailable'])) \n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sales = df_orders[tmp_mask]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's look at the count by statuses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders.order_status.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We'll create an order-level variable indicating purchase conversion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders['is_purchase'] = tmp_mask.map({True: 'Purchase', False: 'Not Purchase'}).astype('category')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orders.is_purchase.value_counts(dropna=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Create first purchase flag**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To handle multiple purchases within the same timestamp, use ranking."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sort by customer and purchase date for correct ranking\n",
        "df_sales = df_sales.sort_values(['customer_unique_id', 'order_purchase_dt'])\n",
        "\n",
        "# Global first purchase flag (with tie-breaking via purchase_rank)\n",
        "df_sales['customer_first_purchase_dt'] = df_sales.groupby('customer_unique_id')['order_purchase_dt'].transform('min')\n",
        "df_sales['purchase_rank'] = df_sales.groupby('customer_unique_id').cumcount()\n",
        "df_sales['sale_is_customer_first_purchase'] = (\n",
        "    (df_sales['order_purchase_dt'] == df_sales['customer_first_purchase_dt']) \n",
        "    & (df_sales['purchase_rank'] == 0)\n",
        ")\n",
        "\n",
        "df_sales.drop(columns=['purchase_rank'], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at the missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sales.explore.detect_anomalies()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Results are as expected."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Enriching Table df_customers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "customer_unique_id isn't unique in df_customers (data characteristic). For analysis, we'll:\n",
        "\n",
        "- Save original table under new name\n",
        "- Remove duplicates from df_customers for user analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_customers_origin = df_customers.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_customers = df_customers.drop_duplicates('customer_unique_id').drop('customer_id', axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### From Table  df_orders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create metrics for each customer:\n",
        "\n",
        "- Order count\n",
        "- Canceled order count\n",
        "- Cancelation rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_orders_agg = df_orders.copy()\n",
        "tmp_df_orders_agg['is_canceled'] = tmp_df_orders_agg['order_status'] == 'Canceled'\n",
        "tmp_df_orders_agg['is_not_delivered'] = tmp_df_orders_agg['order_status'] != 'Delivered'\n",
        "tmp_df_orders_agg['is_customer_issue'] = tmp_df_orders_agg['delivery_issue_reason'] == 'Customer Issue'\n",
        "tmp_df_orders_agg['is_service_issue'] = tmp_df_orders_agg['delivery_issue_reason'] == 'Service Issue'\n",
        "tmp_df_orders_agg = (\n",
        "    tmp_df_orders_agg.groupby('customer_unique_id', as_index=False)\n",
        "    .agg(\n",
        "        orders_cnt = ('order_id', 'nunique')\n",
        "        , canceled_share = ('is_canceled', 'mean')\n",
        "        , canceled_orders_cnt= ('is_canceled', 'sum')\n",
        "        , not_delivered_share = ('is_not_delivered', 'mean')\n",
        "        , customer_issue_share = ('is_customer_issue', 'mean')\n",
        "        , service_issue_share = ('is_service_issue', 'mean')\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check key mismatches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fron.analyze_join_keys(df_orders, tmp_df_reviews_agg, \"order_id\", how='left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Merge tables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_customers = df_customers.merge(tmp_df_orders_agg, on='customer_unique_id', how='left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### From Table  df_sales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create metrics for each customer:\n",
        "\n",
        "- Purchase count\n",
        "- Average delivery time\n",
        "- Average delivery delay\n",
        "- Delayed order rate\n",
        "- Weekend purchase rate\n",
        "- Average inter-purchase time\n",
        "- Average payment count\n",
        "- Total payments\n",
        "- Average order value\n",
        "- Average single payment amount\n",
        "- Installment order rate\n",
        "- Average product count per order\n",
        "- Average unique product count\n",
        "- Average seller count per order\n",
        "- Total product value\n",
        "- Average product value\n",
        "- Average single product value\n",
        "- Average shipping cost\n",
        "- Average order weight\n",
        "- Average order volume\n",
        "- Free shipping rate\n",
        "- Review count\n",
        "- Average review score\n",
        "- Active months count\n",
        "- Max consecutive active months"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create dimensions for each customer:\n",
        "\n",
        "- Installment usage\n",
        "- Payment types\n",
        "- Top 3 purchase weekdays\n",
        "- Top 3 product categories\n",
        "- Top 3 generalized categories\n",
        "- First purchase date"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Top 3 Weekdays**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sales.groupby('customer_unique_id')['purchase_weekday'].nunique().value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Aggregate top 3 weekdays by purchase frequency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "top_purchase_weekdays = (\n",
        "    df_sales.groupby(['customer_unique_id', 'purchase_weekday'], as_index=False, observed=True)\n",
        "    .size()  \n",
        "    .sort_values(by=['customer_unique_id', 'size'], ascending=[True, False]) \n",
        "    .groupby('customer_unique_id')\n",
        "    .head(3) \n",
        ")\n",
        "top_purchase_weekdays = (\n",
        "    top_purchase_weekdays.groupby('customer_unique_id', as_index=False)\n",
        "    .agg(\n",
        "        customer_top_purchase_weekdays = ('purchase_weekday', lambda x: ', '.join(sorted(set(x))))\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Top 3 Payment Types:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "payment_types = (\n",
        "    df_sales.merge(df_payments, on='order_id', how='left')\n",
        ")\n",
        "payment_types.groupby('customer_unique_id')['payment_type'].nunique().value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Concatenate into string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "payment_types = (\n",
        "    payment_types.groupby('customer_unique_id', as_index=False)\n",
        "    .agg(\n",
        "        customer_payment_types = ('payment_type', lambda x: ', '.join(sorted(set(x))))\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Top 3 Product Categories:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "top_product_categories = (\n",
        "    df_sales.merge(df_items, on='order_id', how='left')\n",
        "    .merge(df_products, on='product_id', how='left')\n",
        ")\n",
        "(top_product_categories.drop_duplicates(['customer_unique_id', 'order_id', 'product_category'])\n",
        ".groupby(['customer_unique_id'])['product_category']\n",
        ".nunique()\n",
        ".value_counts()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Aggregate top 3 categories by frequency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "top_product_categories = (\n",
        "    top_product_categories.drop_duplicates(['customer_unique_id', 'order_id', 'product_category'])\n",
        "    .groupby(['customer_unique_id', 'product_category'], as_index=False, observed=True)\n",
        "    .size()  \n",
        "    .sort_values(by=['customer_unique_id', 'size'], ascending=[True, False]) \n",
        "    .groupby('customer_unique_id')\n",
        "    .head(3) \n",
        ")\n",
        "top_product_categories = (\n",
        "    top_product_categories.groupby('customer_unique_id', as_index=False)\n",
        "    .agg(\n",
        "        customer_top_product_categories = ('product_category', lambda x: ', '.join(sorted(set(x))))\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Top 3 Generalized Categories**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "top_general_product_categories = (\n",
        "    df_sales.merge(df_items, on='order_id', how='left')\n",
        "    .merge(df_products, on='product_id', how='left')\n",
        ")\n",
        "(top_general_product_categories.drop_duplicates(['customer_unique_id', 'order_id', 'general_product_category'])\n",
        ".groupby(['customer_unique_id'])['general_product_category']\n",
        ".nunique()\n",
        ".value_counts()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Aggregate top 3 categories by frequency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "top_general_product_categories = (\n",
        "    top_general_product_categories.drop_duplicates(['customer_unique_id', 'order_id', 'general_product_category'])\n",
        "    .groupby(['customer_unique_id', 'general_product_category'], as_index=False, observed=True)\n",
        "    .size()  \n",
        "    .sort_values(by=['customer_unique_id', 'size'], ascending=[True, False]) \n",
        "    .groupby('customer_unique_id')\n",
        "    .head(3) \n",
        ")\n",
        "top_general_product_categories = (\n",
        "    top_general_product_categories.groupby('customer_unique_id', as_index=False)\n",
        "    .agg(\n",
        "        customer_top_general_product_categories = ('general_product_category', lambda x: ', '.join(sorted(set(x))))\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_sales_agg = df_sales.copy()\n",
        "tmp_df_sales_agg['is_delayed'] = tmp_df_sales_agg['is_delayed'] == 'Delayed'\n",
        "tmp_df_sales_agg['is_purchase_weekend'] = tmp_df_sales_agg['purchase_day_type'] == 'Weekend'\n",
        "tmp_df_sales_agg['order_has_installment'] = tmp_df_sales_agg['order_has_installment'] == 'Has Installments'\n",
        "tmp_df_sales_agg['order_is_free_shipping'] = tmp_df_sales_agg['order_is_free_shipping'] == 'Free Shipping'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_sales_agg = (\n",
        "    tmp_df_sales_agg.groupby('customer_unique_id', as_index=False)\n",
        "    .agg(\n",
        "        buys_cnt = ('order_id', 'nunique')\n",
        "        , avg_delivery_time_days = ('delivery_time_days', 'mean')\n",
        "        , avg_delivery_delay_days = ('delivery_delay_days', 'mean')\n",
        "        , delayed_orders_share = ('is_delayed', 'mean')\n",
        "        , purchase_weekend_share = ('is_purchase_weekend', 'mean')\n",
        "        , repeat_purchase_share = ('sale_is_customer_first_purchase', 'mean')\n",
        "        , avg_payments_cnt = ('payments_cnt', 'mean')\n",
        "        , total_customer_payment = ('total_payment', 'sum')\n",
        "        , avg_total_order_payment = ('total_payment', 'mean')\n",
        "        , avg_individual_payment = ('avg_payment', 'mean')\n",
        "        , installment_orders_share = ('order_has_installment', 'mean')\n",
        "        , avg_products_cnt = ('products_cnt', 'mean')\n",
        "        , avg_unique_products_cnt = ('unique_products_cnt', 'mean')\n",
        "        , avg_sellers_cnt = ('sellers_cnt', 'mean')\n",
        "        , avg_order_total_products_price = ('total_products_price', 'mean')\n",
        "        , avg_total_order_price = ('total_order_price', 'mean')\n",
        "        , avg_products_price = ('avg_products_price', 'mean')\n",
        "        , total_products_price = ('total_products_price', 'sum')\n",
        "        , avg_order_total_freight_value = ('total_freight_value', 'mean')\n",
        "        , avg_order_total_weight_kg = ('total_weight_kg', 'mean')\n",
        "        , avg_order_total_volume_cm3 = ('total_volume_cm3', 'mean')\n",
        "        , free_shipping_share = ('order_is_free_shipping', 'mean')\n",
        "        , reviews_cnt = ('reviews_cnt', 'sum')\n",
        "        , customer_avg_reviews_score = ('order_avg_reviews_score', 'mean')      \n",
        "        , avg_distance_km = ('avg_distance_km', 'mean')\n",
        "        , first_purchase_dt = ('order_purchase_dt', 'min')\n",
        "        , last_purchase_dt=('order_purchase_dt', 'max')\n",
        "        , from_first_to_second_days=('order_purchase_dt', lambda x: (x.nsmallest(2).iloc[-1] - x.min()).total_seconds() / (3600*24) if len(x) > 1 else np.nan)\n",
        "        , from_first_to_last_days=('order_purchase_dt', lambda x: (x.max() - x.min()).total_seconds() / (3600*24) if len(x) > 1 else np.nan)\n",
        "    )\n",
        "    .merge(top_purchase_weekdays, on='customer_unique_id', how='left')\n",
        "    .merge(payment_types, on='customer_unique_id', how='left')\n",
        "    .merge(top_product_categories, on='customer_unique_id', how='left')\n",
        "    .merge(top_general_product_categories, on='customer_unique_id', how='left')\n",
        "          \n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We calculated the average value of the column 'sale_is_customer_first_purchase', but to get the proportion of repeat purchases, we need to subtract this value from 1.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_sales_agg['repeat_purchase_share'] = 1 - tmp_df_sales_agg['repeat_purchase_share']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Missing values in dimensions for customers without df_items orders will show 'No Order In Items'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_sales_agg['customer_top_product_categories'] = tmp_df_sales_agg['customer_top_product_categories'].fillna('No Order in Items')\n",
        "tmp_df_sales_agg['customer_top_general_product_categories'] = tmp_df_sales_agg['customer_top_general_product_categories'].fillna('No Order in Items')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_sales_agg['customer_top_purchase_weekdays'] = tmp_df_sales_agg['customer_top_purchase_weekdays'].astype('category')\n",
        "tmp_df_sales_agg['customer_payment_types'] = tmp_df_sales_agg['customer_payment_types'].astype('category')\n",
        "tmp_df_sales_agg['customer_top_product_categories'] = tmp_df_sales_agg['customer_top_product_categories'].astype('category')\n",
        "tmp_df_sales_agg['customer_top_general_product_categories'] = tmp_df_sales_agg['customer_top_general_product_categories'].astype('category')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Inter-purchase Time**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_diff_days = (df_sales[['customer_unique_id', 'order_purchase_dt']]\n",
        "          .sort_values(['customer_unique_id', 'order_purchase_dt'])\n",
        ")\n",
        "tmp_df_diff_days['avg_buys_diff_days'] = (tmp_df_diff_days.groupby(['customer_unique_id'])['order_purchase_dt']\n",
        "                  .diff()\n",
        "                  .apply(lambda x: x.days + x.seconds / (24 * 3600))\n",
        ")\n",
        "tmp_df_diff_days.dropna(subset='avg_buys_diff_days', inplace=True)\n",
        "tmp_df_diff_days = (tmp_df_diff_days.groupby('customer_unique_id', as_index=False)\n",
        "               .agg(avg_buys_diff_days = ('avg_buys_diff_days', 'mean')\n",
        "               )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check key mismatches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fron.analyze_join_keys(tmp_df_sales_agg, tmp_df_diff_days, \"customer_unique_id\", how='left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NA for single-purchase customers (expected)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Merge tables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_sales_agg = tmp_df_sales_agg.merge(tmp_df_diff_days, on='customer_unique_id', how='left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Active Months**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_months_with_buys = (\n",
        "    df_sales.assign(\n",
        "        year_month = lambda x: x.order_purchase_dt.dt.to_period('M')\n",
        "    )\n",
        "    .groupby('customer_unique_id', as_index=False)\n",
        "    .agg(months_with_buys = ('year_month', 'nunique'))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_months_with_buys.months_with_buys.value_counts(dropna=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check key mismatches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fron.analyze_join_keys(tmp_df_sales_agg, tmp_df_months_with_buys, \"customer_unique_id\", how='left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Merge tables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_sales_agg = tmp_df_sales_agg.merge(tmp_df_months_with_buys, on='customer_unique_id', how='left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Consecutive Active Months**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Count streaks of ≥2 months."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_max_months_with_buys = df_sales[['order_purchase_dt', 'customer_unique_id', 'order_id']]\n",
        "tmp_df_max_months_with_buys['year_month'] = tmp_df_max_months_with_buys.order_purchase_dt.dt.to_period('M')\n",
        "tmp_df_max_months_with_buys = tmp_df_max_months_with_buys.drop_duplicates(['customer_unique_id', 'year_month'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_max_months_with_buys = tmp_df_max_months_with_buys.sort_values(['customer_unique_id', 'year_month'])\n",
        "tmp_df_max_months_with_buys['diff'] = tmp_df_max_months_with_buys.groupby('customer_unique_id')['year_month'].diff()\n",
        "tmp_df_max_months_with_buys.dropna(subset='diff', inplace=True)\n",
        "tmp_df_max_months_with_buys.fillna(0, inplace=True)\n",
        "tmp_df_max_months_with_buys['is_diff_one_month'] = tmp_df_max_months_with_buys['diff'] == pd.offsets.MonthEnd(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_max_consecutive_repeats_plus_on(x):\n",
        "    res = x.ne(x.shift()).cumsum()[x].value_counts().max() + 1\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_max_months_with_buys = (\n",
        "    tmp_df_max_months_with_buys.groupby('customer_unique_id')\n",
        "    .agg(max_consecutive_months_with_buys = ('is_diff_one_month', get_max_consecutive_repeats_plus_on))\n",
        "    .dropna()\n",
        "    .astype(int)\n",
        "    .reset_index()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check key mismatches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fron.analyze_join_keys(tmp_df_sales_agg, tmp_df_max_months_with_buys, \"customer_unique_id\", how='left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We have many users who made purchases in only one month, so they have a missing value in the new field. We will replace it with 1 after merging.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Merge tables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_sales_agg = tmp_df_sales_agg.merge(tmp_df_max_months_with_buys, on='customer_unique_id', how='left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Replace NA with 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_sales_agg.max_consecutive_months_with_buys = tmp_df_sales_agg.max_consecutive_months_with_buys.fillna(1).astype(int)\n",
        "tmp_df_sales_agg.max_consecutive_months_with_buys.value_counts(dropna=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Merge with df_customers**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check key mismatches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fron.analyze_join_keys(df_customers, tmp_df_sales_agg, \"customer_unique_id\", how='left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Missing values occur for customers with only canceled orders."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Merge tables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_customers = df_customers.merge(tmp_df_sales_agg, on='customer_unique_id', how='left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### From Table  df_geolocations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check key mismatches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fron.analyze_join_keys(df_customers, df_geolocations, left_on='customer_zip_code_prefix', right_on='geolocation_zip_code_prefix', how='left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we already found out, there are customers whose prefixes are not present in the geolocation table. \n",
        "\n",
        "We need full prefixes only to calculate the distance between the customer and the seller. \n",
        "\n",
        "For geo-analysis, we will use the truncated prefixes. Let's check if there are any missing rows.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fron.analyze_join_keys(df_customers, df_geolocations, left_on='customer_zip_code_prefix_3_digits', right_on='geolocation_zip_code_prefix_3_digits', how='left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With geo-analysis, there will be no problems. The issue is only with calculating the distance. \n",
        "\n",
        "We can try to fill in the coordinates based on the truncated prefixes and calculate the coordinates. \n",
        "\n",
        "However, this will clearly result in significant error, and we want to preserve accuracy. \n",
        "\n",
        "If we fill in these missing values, we will introduce more distortion into the data than gain any benefit. \n",
        "\n",
        "Given that there are few missing rows, we will simply leave them as is and analyze the distance without them.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Merge tables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_customers = df_customers.merge(df_geolocations, left_on='customer_zip_code_prefix', right_on='geolocation_zip_code_prefix', how='left')\n",
        "df_customers.rename(columns={'geolocation_lat': 'lat_customer', 'geolocation_lng': 'lng_customer'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_customers.drop(['geolocation_zip_code_prefix', 'geolocation_zip_code_prefix_3_digits'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at the missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_customers.explore.detect_anomalies()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "All missing values are expected. \n",
        "\n",
        "Missing values are for customers who did not make any successful purchases. \n",
        "\n",
        "We will replace the missing values in the measurements with 'Never Converted'.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_customers['customer_top_purchase_weekdays'] = (\n",
        "    df_customers['customer_top_purchase_weekdays']\n",
        "    .cat.add_categories('Never Converted')\n",
        "    .fillna('Never Converted')\n",
        ")\n",
        "df_customers['customer_payment_types'] = (\n",
        "    df_customers['customer_payment_types']\n",
        "    .cat.add_categories('Never Converted')\n",
        "    .fillna('Never Converted')\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_customers['customer_top_product_categories'] = (\n",
        "    df_customers['customer_top_product_categories']\n",
        "    .cat.add_categories('Never Converted')\n",
        "    .fillna('Never Converted')\n",
        ")\n",
        "df_customers['customer_top_general_product_categories'] = (\n",
        "    df_customers['customer_top_general_product_categories']\n",
        "    .cat.add_categories('Never Converted')\n",
        "    .fillna('Never Converted')\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Customer Segmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Based on customer metrics, we will segment the customers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Monetary Value **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Examine quantiles in the total_customer_payment column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_customers.total_customer_payment.quantile([0, 0.05, 0.25, 0.5, 0.75, 0.95, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create the following segments:\n",
        "\n",
        "- Low value: payments up to 63 R$ inclusive\n",
        "- Medium value: payments from 63 to 182 R$ inclusive\n",
        "- High value: payments above 182 R$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = ['Low', 'Medium', 'High']\n",
        "bins = [-np.inf, 63, 182, np.inf]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_customers['value_segment'] = (\n",
        "    df_customers.total_customer_payment.preproc\n",
        "    .to_categorical(method='custom_bins', labels=labels, bins=bins, fill_na_value='Never Converted')\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Activity**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We identify the following segments:\n",
        "\n",
        "- Non-converted: customers who didn't complete any successful purchases\n",
        "- Core customers:\n",
        "    - Completed 3 or more purchases\n",
        "    - Time between first and last purchase is 60 days or more\n",
        "- Potential core:\n",
        "    - Completed 2 or more purchases\n",
        "    - Time between first and last purchase is 30 days or less\n",
        "- Short-term repeaters:\n",
        "    - Completed more than 2 purchases\n",
        "    - Time between first and last purchase is less than 30 days\n",
        "- One-time buyers: completed only one purchase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "now = df_sales.order_purchase_dt.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "conditions = [\n",
        "    df_customers['first_purchase_dt'].isna() # No Successful Purchases\n",
        "    , (df_customers['buys_cnt'] >= 3) & (df_customers['from_first_to_last_days'] >= 60) # Core\n",
        "    , (df_customers['buys_cnt'] >= 2) & (df_customers['from_first_to_last_days'] >= 30) # Potential Core\n",
        "    , (df_customers['buys_cnt'] >= 2) & (df_customers['from_first_to_last_days'] < 30) # Short-Lived Repeat\n",
        "    , (df_customers['buys_cnt'] == 1) # One-Time\n",
        "]\n",
        "choices = ['Never Converted', 'Core', 'Potential Core', 'Short-Lived Repeat', 'One Time']\n",
        "df_customers['activity_segment'] = np.select(conditions, choices, default='Other')\n",
        "df_customers['activity_segment'] = df_customers['activity_segment'].astype('category')\n",
        "df_customers['activity_segment'].value_counts(dropna=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Examine quantiles in the avg_buys_diff_days column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_customers.avg_buys_diff_days.quantile([0, 0.05, 0.25, 0.5, 0.75, 0.95, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create the following segments:\n",
        "\n",
        "- Weekly \n",
        "- Monthly \n",
        "- Quarterly\n",
        "- Semiannual \n",
        "- Annual "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = ['Weekly', 'Monthly', 'Quarterly', 'Semiannual', 'Annual']\n",
        "bins = [-np.inf, 7, 30, 90, 180, np.inf]\n",
        "df_customers['purchase_freq_segment'] = (\n",
        "    df_customers.avg_buys_diff_days.preproc\n",
        "    .to_categorical(method='custom_bins', labels=labels, bins=bins)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Missing values require two-step replacement as they occur for both non-converted customers and those without any purchases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mask_one_time = df_customers['buys_cnt'] == 1\n",
        "mask_never_converted = df_customers['buys_cnt'].isna()\n",
        "\n",
        "df_customers['purchase_freq_segment'] = (\n",
        "    df_customers['purchase_freq_segment'].cat.add_categories(['Non-Repeating', 'Never Converted'])\n",
        ")\n",
        "\n",
        "df_customers.loc[mask_one_time, 'purchase_freq_segment'] = 'Non-Repeating'\n",
        "df_customers.loc[mask_never_converted, 'purchase_freq_segment'] = 'Never Converted'\n",
        "df_customers['purchase_freq_segment'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Examine quantiles in the from_first_to_second_days column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_customers.from_first_to_second_days.quantile([0, 0.05, 0.25, 0.5, 0.75, 0.95, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create the following segments:\n",
        "\n",
        "- Fast repeaters: repurchase within 14 days\n",
        "- Medium repeaters: repurchase in 14-60 days\n",
        "- Slow repeaters: repurchase after 60 days"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = ['Fast Repeat', 'Medium Repeat', 'Slow Repeat']\n",
        "bins = [-np.inf, 14, 60, np.inf]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_customers['repeat_segment'] = (\n",
        "    df_customers.from_first_to_second_days.preproc\n",
        "    .to_categorical(method='custom_bins', labels=labels, bins=bins)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We replace missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_customers['repeat_segment'] = (\n",
        "    df_customers['repeat_segment'].cat.add_categories(['Non-Repeating', 'Never Converted'])\n",
        ")\n",
        "\n",
        "df_customers.loc[mask_one_time, 'repeat_segment'] = 'Non-Repeating'\n",
        "df_customers.loc[mask_never_converted, 'repeat_segment'] = 'Never Converted'\n",
        "df_customers['repeat_segment'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Loyalty**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Examine quantiles in the customer_avg_reviews_score column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_customers.customer_avg_reviews_score.quantile([0, 0.05, 0.25, 0.5, 0.75, 0.95, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create the following segments:\n",
        "\n",
        "- Critics: average score below 3\n",
        "- Neutral: average score 3-4\n",
        "- Promoters: average score 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = ['Critic', 'Neutral', 'Promoter']\n",
        "bins = [-np.inf, 3, 5, np.inf]\n",
        "df_customers['loyalty_segment'] = (\n",
        "    df_customers.customer_avg_reviews_score.preproc\n",
        "    .to_categorical(method='custom_bins', labels=labels, bins=bins, fill_na_value='Never Converted', right=False)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Risk Segment**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Examine quantiles in the canceled_share column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_customers.canceled_share.quantile([0, 0.05, 0.25, 0.5, 0.75, 0.95, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create the following segments:\n",
        "\n",
        "- Reliable: 0% cancellation rate\n",
        "- Risky: cancellation rate above 0%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = ['Reliable', 'Risky']\n",
        "bins = [-np.inf, 0, np.inf]\n",
        "df_customers['risk_segment'] = (\n",
        "    df_customers.canceled_share.preproc\n",
        "    .to_categorical(method='custom_bins', labels=labels, bins=bins)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Customer Behavioral Characteristics**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Examine quantiles in the purchase_weekend_share column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_customers.purchase_weekend_share.quantile([0, 0.05, 0.25, 0.5, 0.75, 0.95, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create the following segments:\n",
        "\n",
        "- Weekday buyers: 0% weekend purchases\n",
        "- Weekend buyers: weekend purchases above 0%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = ['Weekday', 'Weekend']\n",
        "bins = [-np.inf, 0, np.inf]\n",
        "df_customers['weekday_segment'] = (\n",
        "    df_customers.purchase_weekend_share.preproc\n",
        "    .to_categorical(method='custom_bins', labels=labels, bins=bins, fill_na_value='Never Converted')\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Examine quantiles in the installment_orders_share column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_customers.installment_orders_share.quantile([0, 0.05, 0.25, 0.5, 0.75, 0.95, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create the following segments:\n",
        "\n",
        "- Full payment: 0% installment orders\n",
        "- Installment users: installment orders above 0%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = ['Full Pay', 'Installment']\n",
        "bins = [-np.inf, 0, np.inf]\n",
        "df_customers['installment_segment'] = (\n",
        "    df_customers.installment_orders_share.preproc\n",
        "    .to_categorical(method='custom_bins', labels=labels, bins=bins, fill_na_value='Never Converted')\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Order Characteristics**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Examine quantiles in the avg_products_cnt column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_customers.avg_products_cnt.quantile([0, 0.05, 0.25, 0.5, 0.75, 0.95, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create the following segments:\n",
        "\n",
        "- Single product buyers: average 1 product per order\n",
        "- Multi-product buyers: average 1-2 products per order\n",
        "- Bulk buyers: average more than 2 products per order"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = ['Single Product', 'Multi Product', 'Bulk Buyer']\n",
        "bins = [-np.inf, 1, 2, np.inf]\n",
        "df_customers['products_cnt_segment'] = (\n",
        "    df_customers.avg_products_cnt.preproc\n",
        "    .to_categorical(method='custom_bins', labels=labels, bins=bins, fill_na_value='Never Converted')\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Examine quantiles in the avg_order_total_weight_kg column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_customers.avg_order_total_weight_kg.quantile([0, 0.05, 0.25, 0.5, 0.75, 0.95, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create the following segments:\n",
        "\n",
        "- Light orders: average up to 0.5 kg\n",
        "- Medium orders: average 0.5-2.5 kg\n",
        "- Heavy orders: average more than 2.5 kg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = ['Light', 'Medium', 'Heavy']\n",
        "bins = [-np.inf, 0.5, 2.5, np.inf]\n",
        "df_customers['weight_segment'] = (\n",
        "    df_customers.avg_order_total_weight_kg.preproc\n",
        "    .to_categorical(method='custom_bins', labels=labels, bins=bins, fill_na_value='Never Converted')\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Enriching Table df_products"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### From Table  df_orders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will create the following metrics for each product:\n",
        "\n",
        "- Count of canceled orders containing this product"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_products_canceled = (\n",
        "    df_orders[lambda x: x.order_status == 'Canceled'][['order_id']]\n",
        "    .merge(df_items, on='order_id', how='left')\n",
        "    .groupby('product_id', as_index=False)\n",
        "    .agg(\n",
        "        product_canceled_orders_cnt = ('order_id', 'nunique')\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will merge this with the main products dataframe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check key mismatches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fron.analyze_join_keys(df_products, tmp_df_products_canceled, \"product_id\", how='left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Missing values will appear for products that were not part of canceled orders."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Merge tables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_products = df_products.merge(tmp_df_products_canceled, on='product_id', how='left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### From Table  df_sales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will create the following additional metrics for each product:\n",
        "\n",
        "- Count of orders containing this product\n",
        "- Total units sold of this product\n",
        "- Total sales value for this product\n",
        "- Average quantity of this product per order\n",
        "- Average share of this product in order by quantity\n",
        "- Average share of this product in order by value\n",
        "- Average price of product over all time\n",
        "- Maximum price of product\n",
        "- Minimum price of product\n",
        "- Price range"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_products = (\n",
        "    df_sales[['order_id']].merge(df_items, on='order_id', how='left')\n",
        "    .groupby('product_id', as_index=False)\n",
        "    .agg(\n",
        "        product_sales_cnt = ('order_id', 'nunique')\n",
        "        , total_units_sold = ('order_item_id', 'count')\n",
        "        , total_sales_amount = ('price', 'sum')\n",
        "        , avg_price = ('price', 'mean')\n",
        "        , min_price = ('price', 'min')\n",
        "        , max_price = ('price', 'max')\n",
        "    )\n",
        ")\n",
        "tmp_df_products['price_range'] = tmp_df_products['max_price'] - tmp_df_products['min_price']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will calculate average shares in orders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_products_share = (df_sales[['order_id']].merge(df_items, on='order_id', how='left')\n",
        "                      .groupby(['order_id', 'product_id'], as_index=False)\n",
        "                      .agg(\n",
        "                          product_qty = ('order_item_id', 'count')\n",
        "                          , product_total_price = ('price', 'sum')\n",
        "                      )\n",
        ")\n",
        "tmp_df_products_share['products_cnt'] = tmp_df_products_share.groupby('order_id').product_qty.transform('sum')\n",
        "tmp_df_products_share['order_total_price'] = tmp_df_products_share.groupby('order_id').product_total_price.transform('sum')\n",
        "tmp_df_products_share['product_qty_share_per_order'] = tmp_df_products_share['product_qty'] / tmp_df_products_share['products_cnt']\n",
        "tmp_df_products_share['order_total_price_share_per_order'] = tmp_df_products_share['product_total_price'] / tmp_df_products_share['order_total_price']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_products_share = (tmp_df_products_share.groupby('product_id', as_index=False)\n",
        "                      .agg(\n",
        "                          avg_product_qty_per_order = ('product_qty', 'mean')\n",
        "                          , avg_product_qty_share_per_order = ('product_qty_share_per_order', 'mean')\n",
        "                          , avg_order_total_price_share_per_order = ('order_total_price_share_per_order', 'mean')\n",
        "                      )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Merge tables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check key mismatches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fron.analyze_join_keys(tmp_df_products, tmp_df_products_share, \"product_id\", how='left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Merge tables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_products = tmp_df_products.merge(tmp_df_products_share, on='product_id', how='left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will merge this with the main products dataframe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check key mismatches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fron.analyze_join_keys(df_products, tmp_df_products, \"product_id\", how='left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Missing values will appear for products that were never sold."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Merge tables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_products = df_products.merge(tmp_df_products, on='product_id', how='left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at the missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_products.explore.detect_anomalies()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "All missing values are expected."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Enriching Table df_sellers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### From Tables df_items and df_products"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From Table `df_items` we will select only sales."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check key mismatches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fron.analyze_join_keys(df_items, df_sales[['order_id']], \"order_id\", how='inner')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_items = df_items.merge(df_sales[['order_id']], on='order_id', how='inner')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will add product information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check key mismatches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fron.analyze_join_keys(tmp_df_items, df_products, \"product_id\", how='left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Merge tables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_items_prods = tmp_df_items.merge(df_products, on='product_id', how='left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will create the following metrics for each seller:\n",
        "\n",
        "- Total products sold\n",
        "- Count of unique products sold\n",
        "- Number of orders\n",
        "- Total sales value\n",
        "- Average carrier handoff delay\n",
        "- Average number of items per order\n",
        "- Average order value\n",
        "- Average item price\n",
        "- Average product weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_items_prods_agg_1 = (\n",
        "    tmp_df_items_prods.groupby('seller_id', as_index=False)\n",
        "    .agg(\n",
        "        products_cnt = ('product_id', 'count')\n",
        "        , unique_products_cnt = ('product_id', 'nunique')\n",
        "        , orders_cnt = ('order_id', 'nunique')\n",
        "        , revenue = ('price', 'sum')\n",
        "        , avg_carrier_delivery_delay_days = ('carrier_delivery_delay_days', 'mean')\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_items_prods_agg_2 = (\n",
        "    tmp_df_items_prods.groupby(['seller_id', 'order_id'], as_index=False)\n",
        "    .agg(\n",
        "        products_cnt = ('product_id', 'count')\n",
        "        , order_total_price = ('price', 'sum')\n",
        "        , avg_product_price = ('price', 'mean')\n",
        "    )\n",
        "    .groupby('seller_id', as_index=False)\n",
        "    .agg(\n",
        "        avg_prouducts_cnt = ('products_cnt', 'mean')\n",
        "        , avg_order_total_price = ('order_total_price', 'mean')\n",
        "        , avg_product_price = ('avg_product_price', 'mean')\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Important note for average weight calculation:\n",
        "\n",
        "- We must remove duplicates to calculate averages based on unique products only."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_items_prods_agg_3 = (\n",
        "     tmp_df_items_prods.drop_duplicates(subset = ['seller_id', 'product_id'])\n",
        "     .groupby('seller_id', as_index=False)\n",
        "     .agg(\n",
        "          avg_product_weight_kg = ('product_weight_g', 'mean')\n",
        "     )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_items_prods_agg_3['avg_product_weight_kg'] = (tmp_df_items_prods_agg_3['avg_product_weight_kg'] / 1000).round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will merge intermediate dataframes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fron.analyze_join_keys(tmp_df_items_prods_agg_1, tmp_df_items_prods_agg_2, \"seller_id\", how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_items_prods_agg = tmp_df_items_prods_agg_1.merge(tmp_df_items_prods_agg_2, on='seller_id', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fron.analyze_join_keys(tmp_df_items_prods_agg, tmp_df_items_prods_agg_3, \"seller_id\", how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_df_items_prods_agg = tmp_df_items_prods_agg.merge(tmp_df_items_prods_agg_3, on='seller_id', how='left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will add new fields to df_sellers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check key mismatches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fron.analyze_join_keys(df_sellers, tmp_df_items_prods_agg, \"seller_id\", how='left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sellers whose products were never purchased (or whose orders were canceled) will have missing values. This is expected."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Merge tables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sellers = df_sellers.merge(tmp_df_items_prods_agg, on='seller_id', how='left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### From Table  df_geolocations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check key mismatches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fron.analyze_join_keys(df_sellers, df_geolocations, left_on='seller_zip_code_prefix', right_on='geolocation_zip_code_prefix', how='left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As previously established, some sellers' zip prefixes are missing from the geolocation table."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will check using truncated prefixes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fron.analyze_join_keys(df_sellers, df_geolocations, left_on='seller_zip_code_prefix_3_digits', right_on='geolocation_zip_code_prefix_3_digits', how='left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will handle this the same way as with customers:\n",
        "\n",
        "- Keep as-is for geo-analysis (no missing data)\n",
        "- Maintain precision for distance calculations (accept missing values)\n",
        "- Use left join to preserve all sellers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sellers = df_sellers.merge(df_geolocations, left_on='seller_zip_code_prefix', right_on='geolocation_zip_code_prefix', how='left')\n",
        "df_sellers.rename(columns={'geolocation_lat': 'lat_seller', 'geolocation_lng': 'lng_seller'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sellers.drop(['geolocation_zip_code_prefix', 'geolocation_zip_code_prefix_3_digits'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at the missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sellers.explore.detect_anomalies()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will clear temporary variables from memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for var_name in list(globals().keys()):\n",
        "    if var_name.startswith('tmp_'):\n",
        "        del globals()[var_name]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "remove-cell"
        ]
      },
      "source": [
        "%run ../../_post_run.ipynb"
      ],
      "outputs": []
    }
  ]
}